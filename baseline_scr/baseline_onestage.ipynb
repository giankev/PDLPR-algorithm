{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"working_on_kaggle = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:58:41.492684Z","iopub.execute_input":"2025-07-17T05:58:41.493567Z","iopub.status.idle":"2025-07-17T05:58:41.497062Z","shell.execute_reply.started":"2025-07-17T05:58:41.493534Z","shell.execute_reply":"2025-07-17T05:58:41.496426Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"if working_on_kaggle:\n    !pip install --quiet gdown\n    !apt-get install -y fonts-noto-cjk > /dev/null\n\n    import os\n    from kaggle_secrets import UserSecretsClient\n\n    # Recupera il token in modo sicuro\n    user_secrets = UserSecretsClient()\n    token = user_secrets.get_secret(\"pddlr_token\")\n\n    # Dati GitHub\n    username = \"giankev\"\n    repo_name = \"PDDLR-algorithm\"\n\n    # URL di clonazione con autenticazione via token\n    git_url = f\"https://{username}:{token}@github.com/{username}/{repo_name}.git\"\n\n    # Clonazione\n    os.system(f\"git clone --branch novelty {git_url} /kaggle/working/{repo_name}\")\n    %cd /kaggle/working/PDDLR-algorithm/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:58:41.498060Z","iopub.execute_input":"2025-07-17T05:58:41.498431Z","iopub.status.idle":"2025-07-17T05:58:41.514881Z","shell.execute_reply.started":"2025-07-17T05:58:41.498400Z","shell.execute_reply":"2025-07-17T05:58:41.514327Z"}},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport tarfile\nimport shutil\nimport random\nimport math\nimport warnings\nimport gdown\nimport cv2\n\nimport numpy as np\nimport pandas as pd\nimport yaml\nfrom PIL import Image, ImageDraw, ImageFilter\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset \nfrom torchvision import transforms\nfrom torchvision.transforms.functional import to_pil_image\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torchvision import models\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:58:41.515584Z","iopub.execute_input":"2025-07-17T05:58:41.515756Z","iopub.status.idle":"2025-07-17T05:58:41.530720Z","shell.execute_reply.started":"2025-07-17T05:58:41.515743Z","shell.execute_reply":"2025-07-17T05:58:41.529987Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"# Globals","metadata":{}},{"cell_type":"code","source":"NUM_WORKERS = 0\nSEED = 42\nBATCH_SIZE = 64\nVAL_SPLIT_SIZE = 0.2\nEPOCHS = 25\nNUM_SAMPLES = 200\n\narchive_path_train = \"/kaggle/working/datasets/ccpd_train.tar\"\narchive_path_test = \"/kaggle/working/datasets/ccpd_test.tar\"\nextract_path = \"/kaggle/working\"\nfolder_path = \"/kaggle/working/ccpd_subset_base/train\"\nsubfolders = [\"base\", \"blur\", \"challenge\", \"db\", \"fn\", \"rotate\", \"tilt\", \"weather\"]\n\nPROVINCES = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\",\"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n\nALPHA = ['A','B','C','D','E','F','G','H','J','K', 'L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z','O']\n\nADS = ['A','B','C','D','E','F','G','H','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9','O']\n\n\nunique_chars = set(PROVINCES[:-1] + ALPHA[:-1] + ADS[:-1])  # escludi 'O'\nchar_list = sorted(list(unique_chars))  # ordinamento per coerenza\nchar_list = [\"-\"] + char_list\nchar2idx = {char: i for i, char in enumerate(char_list)}\nidx2char = {i: c for c, i in char2idx.items()}\n\nN_CLASSES = len(char_list)\nPLATE_LENGTH = 7 # Lunghezza standard delle targhe cinesi\n\nMEAN, STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n\n# Imposta il seed per la riproducibilità\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# Seleziona il device (GPU se disponibile)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nprint(f\"Number of character classes: {N_CLASSES}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:58:41.532442Z","iopub.execute_input":"2025-07-17T05:58:41.532664Z","iopub.status.idle":"2025-07-17T05:58:41.555842Z","shell.execute_reply.started":"2025-07-17T05:58:41.532648Z","shell.execute_reply":"2025-07-17T05:58:41.555249Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nNumber of character classes: 68\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"def extract_tar_archive(archive_path, destination_path):\n\n    print(f\"Extracting the tar archive in:{archive_path}\")\n    with tarfile.open(archive_path, \"r\") as tar:\n        tar.extractall(path=destination_path)\n\n    print(f\"Archive extracted in: {destination_path}\")\n\ndef delete_tar_archive(path_tar_archive):\n\n    if os.path.exists(path_tar_archive):\n        shutil.rmtree(path_tar_archive)\n        print(f\"Folder eliminated: {path_tar_archive}\")\n    else:\n        print(f\"Folder not found: {path_tar_archive}\")\n\ndef set_seed(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    \ndef decode_plate_from_path(s):\n    idx   = list(map(int, s.split(\"_\")))\n    try:\n        return PROVINCES[idx[0]] + ALPHA[idx[1]] + \"\".join(ADS[i] for i in idx[2:])\n    except Exception:\n        return None\n\ndef split_bbox(bbox_str):\n    coords = bbox_str.replace('___', '_').split('_')\n    return tuple(map(int, coords))\n\ndef create_dataframe(folder_path):\n    rows   = []\n\n    for fname in os.listdir(folder_path):\n        if not fname.endswith(\".jpg\"): continue\n    \n        parts = fname[:-4].split(\"-\")\n        if len(parts) < 6: continue\n    \n        x1,y1,x2,y2 = split_bbox(parts[2])\n        plate = decode_plate_from_path(parts[4])\n    \n        rows.append({\n            \"image_path\": os.path.join(folder_path, fname),\n            \"x1_bbox\": x1, \"y1_bbox\": y1,\n            \"x2_bbox\": x2, \"y2_bbox\": y2,\n            \"plate_number\": plate\n        })\n\n    return pd.DataFrame(rows)\n\ndef encode_plate(plate_str, length=PLATE_LENGTH):\n    \"\"\"Codifica una stringa di targa in un array di indici.\"\"\"\n    # Se la targa è più lunga, viene troncata\n    plate_str = plate_str[:length]\n    # Se è più corta, viene riempita con il carattere di padding '-'\n    padded_plate = plate_str.ljust(length, '-')\n    \n    encoded = [char2idx[char] for char in padded_plate]\n    return encoded\n\ndef decode_plate(plate_indices):\n    \"\"\"Decodifica una lista di indici in una stringa di targa.\"\"\"\n    return \"\".join([idx2char[int(idx)] for idx in plate_indices if idx != char2idx['-']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:58:41.556502Z","iopub.execute_input":"2025-07-17T05:58:41.556727Z","iopub.status.idle":"2025-07-17T05:58:41.572295Z","shell.execute_reply.started":"2025-07-17T05:58:41.556701Z","shell.execute_reply":"2025-07-17T05:58:41.571609Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"## Download and extraction\n","metadata":{}},{"cell_type":"code","source":"!gdown --folder https://drive.google.com/drive/u/1/folders/1Qirh0lsjdsroLHEmJDtS6sVXPQKalW6j -O datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:58:41.572897Z","iopub.execute_input":"2025-07-17T05:58:41.573076Z","iopub.status.idle":"2025-07-17T05:59:14.625055Z","shell.execute_reply.started":"2025-07-17T05:58:41.573061Z","shell.execute_reply":"2025-07-17T05:59:14.624335Z"}},"outputs":[{"name":"stdout","text":"Retrieving folder contents\nProcessing file 1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X ccpd_test.tar\nProcessing file 1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_ ccpd_train.tar\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X\nFrom (redirected): https://drive.google.com/uc?id=1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X&confirm=t&uuid=ecfaa24c-5851-49ee-8ca9-1e6f60c85c84\nTo: /kaggle/working/datasets/ccpd_test.tar\n100%|█████████████████████████████████████████| 557M/557M [00:04<00:00, 134MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_\nFrom (redirected): https://drive.google.com/uc?id=1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_&confirm=t&uuid=34a9e3f5-9912-484d-a113-d67cfd8f95f7\nTo: /kaggle/working/datasets/ccpd_train.tar\n100%|███████████████████████████████████████| 3.76G/3.76G [00:23<00:00, 158MB/s]\nDownload completed\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"extract_tar_archive(archive_path_train, extract_path)\nextract_tar_archive(archive_path_test, extract_path)\ndelete_tar_archive(\"/kaggle/working/datasets\")\nnum_files = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n\nprint(f\" Number of images in '{folder_path}': {num_files}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:59:14.626286Z","iopub.execute_input":"2025-07-17T05:59:14.626939Z","iopub.status.idle":"2025-07-17T05:59:36.284450Z","shell.execute_reply.started":"2025-07-17T05:59:14.626904Z","shell.execute_reply":"2025-07-17T05:59:36.283697Z"}},"outputs":[{"name":"stdout","text":"Extracting the tar archive in:/kaggle/working/datasets/ccpd_train.tar\nArchive extracted in: /kaggle/working\nExtracting the tar archive in:/kaggle/working/datasets/ccpd_test.tar\nArchive extracted in: /kaggle/working\nFolder eliminated: /kaggle/working/datasets\n Number of images in '/kaggle/working/ccpd_subset_base/train': 50000\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"df = create_dataframe(folder_path)\nprint(\"Rows number:\", len(df))\nprint(\"Columns numner:\", df.shape[1])\nprint(\"Shape:\", df.shape)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:59:36.285171Z","iopub.execute_input":"2025-07-17T05:59:36.285478Z","iopub.status.idle":"2025-07-17T05:59:36.659214Z","shell.execute_reply.started":"2025-07-17T05:59:36.285454Z","shell.execute_reply":"2025-07-17T05:59:36.658564Z"}},"outputs":[{"name":"stdout","text":"Rows number: 50000\nColumns numner: 6\nShape: (50000, 6)\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"                                          image_path  x1_bbox  y1_bbox  \\\n0  /kaggle/working/ccpd_subset_base/train/0228125...      229      541   \n1  /kaggle/working/ccpd_subset_base/train/0227969...      218      482   \n2  /kaggle/working/ccpd_subset_base/train/0175167...      250      493   \n3  /kaggle/working/ccpd_subset_base/train/0562128...      141      486   \n4  /kaggle/working/ccpd_subset_base/train/0158333...      142      469   \n\n   x2_bbox  y2_bbox plate_number  \n0      475      638      皖AR5521  \n1      532      579      皖AT7D18  \n2      466      582      豫HZZ988  \n3      525      626      沪BDD871  \n4      326      565      皖AL222V  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>x1_bbox</th>\n      <th>y1_bbox</th>\n      <th>x2_bbox</th>\n      <th>y2_bbox</th>\n      <th>plate_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0228125...</td>\n      <td>229</td>\n      <td>541</td>\n      <td>475</td>\n      <td>638</td>\n      <td>皖AR5521</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0227969...</td>\n      <td>218</td>\n      <td>482</td>\n      <td>532</td>\n      <td>579</td>\n      <td>皖AT7D18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0175167...</td>\n      <td>250</td>\n      <td>493</td>\n      <td>466</td>\n      <td>582</td>\n      <td>豫HZZ988</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0562128...</td>\n      <td>141</td>\n      <td>486</td>\n      <td>525</td>\n      <td>626</td>\n      <td>沪BDD871</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0158333...</td>\n      <td>142</td>\n      <td>469</td>\n      <td>326</td>\n      <td>565</td>\n      <td>皖AL222V</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":60},{"cell_type":"markdown","source":"## DataLoader \n","metadata":{}},{"cell_type":"code","source":"class CCPDDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Carica l'immagine\n        try:\n            image = Image.open(row['image_path']).convert(\"RGB\")\n            img_w, img_h = image.size\n        except FileNotFoundError:\n            # Crea un'immagine fittizia se il percorso non è valido (per debug)\n            print(f\"Warning: File not found at {row['image_path']}. Using a dummy image.\")\n            image = Image.new('RGB', (300, 300), color = 'red')\n            img_w, img_h = image.size\n\n        # Normalizza le coordinate del BBox (da pixel a [0, 1])\n        x1, y1 = row['x1_bbox'] / img_w, row['y1_bbox'] / img_h\n        x2, y2 = row['x2_bbox'] / img_w, row['y2_bbox'] / img_h\n        bbox = torch.tensor([x1, y1, x2, y2], dtype=torch.float32)\n\n        # Codifica la targa\n        plate_str = row['plate_number']\n        plate_encoded = encode_plate(plate_str, length=PLATE_LENGTH)\n        plate = torch.tensor(plate_encoded, dtype=torch.long)\n\n        # Applica le trasformazioni all'immagine\n        if self.transforms:\n            image = self.transforms(image)\n            \n        return {'image': image, 'bbox': bbox, 'plate': plate }\n\ntrain_df, val_df = train_test_split(df, test_size=VAL_SPLIT_SIZE, random_state=SEED)\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(MEAN, STD)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(MEAN, STD)\n    ]),\n}\n\ntrain_dataset = CCPDDataset(train_df, transforms=data_transforms['train'])\nval_dataset = CCPDDataset(val_df, transforms=data_transforms['val'])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:59:36.660233Z","iopub.execute_input":"2025-07-17T05:59:36.660601Z","iopub.status.idle":"2025-07-17T05:59:44.291387Z","shell.execute_reply.started":"2025-07-17T05:59:36.660576Z","shell.execute_reply":"2025-07-17T05:59:44.290286Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class MobileNetBaseline(nn.Module):\n    def __init__(self, n_classes, plate_length=PLATE_LENGTH):\n        super().__init__()\n        \n        # 1. Backbone (Feature Extractor)\n        # Carichiamo MobileNetV2 pre-addestrata su ImageNet\n        mobilenet = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n        # Rimuoviamo il classificatore originale\n        self.backbone = mobilenet.features\n        \n        # Aggiungiamo un layer di pooling per avere un vettore di feature di dimensione fissa\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # L'output di MobileNetV2 dopo il pooling è di 1280 features\n        feature_size = 1280\n        \n        # 2. Testa di Regressione per il Bounding Box (4 coordinate)\n        self.bbox_head = nn.Sequential(\n            nn.Linear(feature_size, 256),\n            nn.ReLU(),\n            nn.Linear(256, 4),\n            nn.Sigmoid() # Sigmoide per mappare l'output tra 0 e 1\n        )\n        \n        # 3. Testa di Classificazione per i Caratteri della Targa\n        # Creiamo una \"testa\" di classificazione per ogni carattere della targa\n        self.char_heads = nn.ModuleList([\n            nn.Linear(feature_size, n_classes) for _ in range(plate_length)\n        ])\n\n    def forward(self, x):\n        # Passaggio attraverso il backbone\n        features = self.backbone(x)\n        features = self.pool(features)\n        features = torch.flatten(features, 1) # Da (batch, 1280, 1, 1) a (batch, 1280)\n        \n        # Predizione del BBox\n        bbox_pred = self.bbox_head(features)\n        \n        # Predizione dei caratteri\n        char_preds = []\n        for head in self.char_heads:\n            char_preds.append(head(features))\n        \n        # Combina le predizioni dei caratteri in un unico tensore\n        # L'output avrà dimensione (batch_size, plate_length, n_classes)\n        plate_pred = torch.stack(char_preds, dim=1)\n        \n        return bbox_pred, plate_pred\n\ndef batch_iou_xyxy(pred_boxes, true_boxes, eps=1e-6):\n    \"\"\"\n    pred_boxes, true_boxes: (N,4) in [x1,y1,x2,y2].\n    Restituisce IoU per ciascun elemento del batch: (N,).\n    \"\"\"\n    # Intersezione\n    x1 = torch.max(pred_boxes[:, 0], true_boxes[:, 0])\n    y1 = torch.max(pred_boxes[:, 1], true_boxes[:, 1])\n    x2 = torch.min(pred_boxes[:, 2], true_boxes[:, 2])\n    y2 = torch.min(pred_boxes[:, 3], true_boxes[:, 3])\n\n    inter_w = (x2 - x1).clamp(min=0)\n    inter_h = (y2 - y1).clamp(min=0)\n    inter = inter_w * inter_h\n\n    # Aree\n    area_p = (pred_boxes[:, 2] - pred_boxes[:, 0]).clamp(min=0) * \\\n             (pred_boxes[:, 3] - pred_boxes[:, 1]).clamp(min=0)\n    area_t = (true_boxes[:, 2] - true_boxes[:, 0]).clamp(min=0) * \\\n             (true_boxes[:, 3] - true_boxes[:, 1]).clamp(min=0)\n\n    union = area_p + area_t - inter\n    iou = inter / (union + eps)\n    return iou\n\ndef bbox_to_xyxy(bboxes_cxcywh):\n    \"\"\"\n    Converte le coordinate dei bounding box dal formato (centro_x, centro_y, larghezza, altezza)\n    al formato (x1, y1, x2, y2).\n    \"\"\"\n    cx, cy, w, h = bboxes_cxcywh.unbind(-1)\n    x1 = cx - 0.5 * w\n    y1 = cy - 0.5 * h\n    x2 = cx + 0.5 * w\n    y2 = cy + 0.5 * h\n    return torch.stack([x1, y1, x2, y2], dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:59:44.295121Z","iopub.execute_input":"2025-07-17T05:59:44.295419Z","iopub.status.idle":"2025-07-17T05:59:44.306141Z","shell.execute_reply.started":"2025-07-17T05:59:44.295402Z","shell.execute_reply":"2025-07-17T05:59:44.305282Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"#  Istanziazione Modello, Loss e Ottimizzatore\nmodel = MobileNetBaseline(n_classes=N_CLASSES, plate_length=PLATE_LENGTH).to(device)\n\nloss_bbox_fn = nn.L1Loss()\nloss_plate_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Directory per checkpoint\nbest_seq_acc = -1.0   # userà la sequence accuracy come metrica \"migliore\"\n# Se preferisci usare la val loss: imposta best_seq_acc = float('inf') e cambia condizione più sotto.\n\n#  Ciclo di Addestramento\nprint(\"Starting training...\")\nfor epoch in range(EPOCHS):\n    # --- Training Phase ---\n    model.train()\n    total_train_loss = 0.0\n    \n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Training]\"):\n        images = batch['image'].to(device)\n        true_bboxes = batch['bbox'].to(device)\n        true_plates = batch['plate'].to(device)\n        \n        pred_bboxes, pred_plates_logits = model(images)\n        \n        loss_bbox = loss_bbox_fn(pred_bboxes, true_bboxes)\n        loss_plate = loss_plate_fn(\n            pred_plates_logits.view(-1, N_CLASSES),\n            true_plates.view(-1)\n        )\n        total_loss = loss_bbox + loss_plate\n        \n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n        \n        total_train_loss += total_loss.item()\n        \n    avg_train_loss = total_train_loss / len(train_loader)\n\n    # --- Validation Phase ---\n    model.eval()\n    total_val_loss = 0.0\n    \n    correct_chars = 0\n    total_chars = 0\n    \n    total_samples = 0\n    seq_correct = 0\n    \n    iou70_count = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Validation]\"):\n            images = batch['image'].to(device)\n            true_bboxes = batch['bbox'].to(device)\n            true_plates = batch['plate'].to(device)\n            \n            pred_bboxes, pred_plates_logits = model(images)\n            \n            # Loss\n            loss_bbox = loss_bbox_fn(pred_bboxes, true_bboxes)\n            loss_plate = loss_plate_fn(pred_plates_logits.view(-1, N_CLASSES), true_plates.view(-1))\n            total_loss = loss_bbox + loss_plate\n            total_val_loss += total_loss.item()\n\n            # --- Metriche ---\n            # Char accuracy (già presente)\n            _, predicted_indices = torch.max(pred_plates_logits, dim=2)\n            correct_chars += (predicted_indices == true_plates).sum().item()\n            total_chars += true_plates.numel()\n\n            # Sequence accuracy: tutti i caratteri corretti\n            batch_seq_correct = (predicted_indices == true_plates).all(dim=1)  # (B,)\n            seq_correct += batch_seq_correct.sum().item()\n            batch_size = true_plates.size(0)\n            total_samples += batch_size\n\n            # IoU > 0.7\n            pred_xyxy = bbox_to_xyxy(pred_bboxes)\n            true_xyxy = bbox_to_xyxy(true_bboxes)\n            batch_iou = batch_iou_xyxy(pred_xyxy, true_xyxy)  # (B,)\n            iou70_count += (batch_iou > 0.7).sum().item()\n    \n    # Aggregazioni metriche\n    avg_val_loss = total_val_loss / len(val_loader)\n    char_accuracy = 100.0 * correct_chars / total_chars\n    seq_accuracy = 100.0 * seq_correct / total_samples\n    iou70_pct = 100.0 * iou70_count / total_samples\n\n    print( f\"Epoch {epoch+1}/{EPOCHS} -> \" f\"Train Loss: {avg_train_loss:.4f} | \" f\"Val Loss: {avg_val_loss:.4f} | \"\n    f\"Val Char Acc: {char_accuracy:.2f}% | \"f\"Val Seq Acc: {seq_accuracy:.2f}% | \"f\"Val IoU>0.7: {iou70_pct:.2f}%\")\n\n    # --- Checkpoint: salva se sequence accuracy migliora ---\n    if seq_accuracy > best_seq_acc:\n        best_seq_acc = seq_accuracy\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f\"  ➜ Nuovo best! Modello salvato!\")\n\nprint(\"\\nTraining finished!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T05:59:44.306900Z","iopub.execute_input":"2025-07-17T05:59:44.307174Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81af83a52d604c2f9de6895e786814c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74960dcaefc43cf8cf685f9b04b5e40"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/25 -> Train Loss: 1.5108 | Val Loss: 0.8446 | Val Char Acc: 75.23% | Val Seq Acc: 9.75% | Val IoU>0.7: 98.45%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d6ebf6138ac48e7baaaa36dc7abfac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edd541d72a6a49cabdc08b3f4113c147"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/25 -> Train Loss: 0.5967 | Val Loss: 0.4463 | Val Char Acc: 87.16% | Val Seq Acc: 43.25% | Val IoU>0.7: 99.62%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47659cd231134497b338dade276e33de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3345fac088914ad0923bd0b878e60588"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/25 -> Train Loss: 0.3421 | Val Loss: 0.3059 | Val Char Acc: 91.26% | Val Seq Acc: 60.15% | Val IoU>0.7: 99.87%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b09274ea83074433938723d878e67e7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 4/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa0036e4baa6438b955f827b517fbb30"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/25 -> Train Loss: 0.2359 | Val Loss: 0.2476 | Val Char Acc: 92.83% | Val Seq Acc: 66.66% | Val IoU>0.7: 99.86%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69cbcffd5d7c41cbb593a7cc363d4666"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 5/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ce44e5f01f4d638ce139cd73a75c48"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/25 -> Train Loss: 0.1809 | Val Loss: 0.2130 | Val Char Acc: 93.92% | Val Seq Acc: 71.31% | Val IoU>0.7: 99.93%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3061ee1baeca409c8cff15ef9b1468df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 6/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8515ceed4c24104b615eda573447fcc"}},"metadata":{}},{"name":"stdout","text":"Epoch 6/25 -> Train Loss: 0.1471 | Val Loss: 0.2097 | Val Char Acc: 94.25% | Val Seq Acc: 72.52% | Val IoU>0.7: 99.93%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86bbdba6b8444e1788a2e020ab434ce3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 7/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8860319af59d4717909498debd985b5b"}},"metadata":{}},{"name":"stdout","text":"Epoch 7/25 -> Train Loss: 0.1240 | Val Loss: 0.2054 | Val Char Acc: 94.24% | Val Seq Acc: 72.26% | Val IoU>0.7: 99.95%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c8bd14c2ba4e24acf6b62237578049"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 8/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe062a56cd8b4eccb2de5d90c08c84bb"}},"metadata":{}},{"name":"stdout","text":"Epoch 8/25 -> Train Loss: 0.1077 | Val Loss: 0.1777 | Val Char Acc: 95.24% | Val Seq Acc: 77.01% | Val IoU>0.7: 99.95%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9e0bd9b557b4859a5262429b72f5a5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 9/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2b163c5b0b54f4ca8b7fe04198dbb60"}},"metadata":{}},{"name":"stdout","text":"Epoch 9/25 -> Train Loss: 0.0955 | Val Loss: 0.1750 | Val Char Acc: 95.32% | Val Seq Acc: 77.74% | Val IoU>0.7: 99.97%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e781a0a80f864aa9adaaf39d5bd62c02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 10/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cab279a4d65f4eea94b715e132724d08"}},"metadata":{}},{"name":"stdout","text":"Epoch 10/25 -> Train Loss: 0.0857 | Val Loss: 0.1574 | Val Char Acc: 95.88% | Val Seq Acc: 80.03% | Val IoU>0.7: 99.98%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69c4979247354446932a38b69f2fff39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 11/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202fc6cff75b4b60abdba3eb14104caf"}},"metadata":{}},{"name":"stdout","text":"Epoch 11/25 -> Train Loss: 0.0764 | Val Loss: 0.1731 | Val Char Acc: 95.47% | Val Seq Acc: 78.11% | Val IoU>0.7: 99.90%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58a85f47f1414d2cafd553ea8a002a8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 12/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f38137916e462db1918a0b6db351d3"}},"metadata":{}},{"name":"stdout","text":"Epoch 12/25 -> Train Loss: 0.0709 | Val Loss: 0.1578 | Val Char Acc: 95.99% | Val Seq Acc: 80.83% | Val IoU>0.7: 99.95%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c7fa8af5ff4458e83072ff0a93b7510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 13/25 [Validation]:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eba9bea265d42c89c302e225eb2a848"}},"metadata":{}},{"name":"stdout","text":"Epoch 13/25 -> Train Loss: 0.0656 | Val Loss: 0.1643 | Val Char Acc: 95.67% | Val Seq Acc: 79.09% | Val IoU>0.7: 99.94%\n  ➜ Nuovo best! Modello salvato!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14/25 [Training]:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e515667d180d493eacf4dfbf158ea5c0"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"# Test set","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, test_loader, loss_bbox_fn, loss_plate_fn, device):\n    \"\"\"\n    Esegue la valutazione del modello su un dato test_loader e restituisce le metriche.\n    \"\"\"\n    model.eval()  # Imposta il modello in modalità valutazione. [2, 7, 9]\n\n    # Inizializzazione delle metriche per questa esecuzione\n    total_loss = 0.0\n    correct_chars, total_chars = 0, 0\n    seq_correct, total_samples = 0, 0\n    iou70_count = 0\n\n    # Disabilita il calcolo dei gradienti per efficienza\n    with torch.no_grad(): #. [11]\n        for batch in tqdm(test_loader, desc=f\"[Testing on {test_loader.dataset.name}]\"):\n            images = batch['image'].to(device)\n            true_bboxes = batch['bbox'].to(device)\n            true_plates = batch['plate'].to(device)\n            \n            # Forward pass\n            pred_bboxes, pred_plates_logits = model(images)\n            \n            # Calcolo Loss\n            loss = loss_bbox_fn(pred_bboxes, true_bboxes) + \\\n                   loss_plate_fn(pred_plates_logits.view(-1, N_CLASSES), true_plates.view(-1))\n            total_loss += loss.item()\n\n            # Calcolo Metriche\n            _, predicted_indices = torch.max(pred_plates_logits, dim=2)\n            correct_chars += (predicted_indices == true_plates).sum().item()\n            total_chars += true_plates.numel()\n            \n            seq_correct += (predicted_indices == true_plates).all(dim=1).sum().item()\n            total_samples += true_plates.size(0)\n\n            pred_xyxy = bbox_to_xyxy(pred_bboxes)\n            true_xyxy = bbox_to_xyxy(true_bboxes)\n            batch_iou = batch_iou_xyxy(pred_xyxy, true_xyxy)\n            iou70_count += (batch_iou > 0.7).sum().item()\n\n    # Aggregazione finale delle metriche\n    if not total_samples: # Evita divisione per zero se il dataset è vuoto\n        return {\n            \"Avg Loss\": float('inf'), \"Char Acc (%)\": 0,\n            \"Seq Acc (%)\": 0, \"IoU>0.7 (%)\": 0\n        }\n\n    results = {\n        \"Avg Loss\": total_loss / len(test_loader),\n        \"Char Acc (%)\": 100.0 * correct_chars / total_chars,\n        \"Seq Acc (%)\": 100.0 * seq_correct / total_samples,\n        \"IoU>0.7 (%)\": 100.0 * iou70_count / total_samples\n    }\n    return results\n\n\n# --- Setup Iniziale (Caricamento Modello) ---\nprint(\"Caricamento del modello migliore per il test...\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nMODEL_PATH = '/kaggle/working/best_model.pth'\n\n# Istanzia il modello una sola volta\nmodel = MobileNetBaseline(n_classes=N_CLASSES, plate_length=PLATE_LENGTH).to(device)\nmodel.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n\n# Definisci le funzioni di loss una sola volta\nloss_bbox_fn = nn.L1Loss()\nloss_plate_fn = nn.CrossEntropyLoss()\n\n\n# --- Ciclo di Test su tutte le Sottocartelle ---\nTEST_ROOT_DIR = '/kaggle/working/ccpd_test'\nsubfolders = [\"base\", \"blur\", \"challenge\", \"db\", \"fn\", \"rotate\", \"tilt\", \"weather\"]\nall_results = {}\n\nprint(\"\\nAvvio del test su tutte le categorie...\")\nfor folder_name in subfolders:\n    print(f\"\\n--- Valutazione della categoria: {folder_name.upper()} ---\")\n    \n    # 1. Crea il dataset e il dataloader per la sottocartella corrente\n    test_df = create_dataframe(f'{TEST_ROOT_DIR}/{folder_name}')\n    \n    if test_df.empty:\n        print(f\"Attenzione: Nessuna immagine trovata in {folder_name}. Salto questa categoria.\")\n        continue\n        \n    test_dataset = CCPDDataset(test_df, transforms=data_transforms['val'])\n    # Assegno un nome al dataset per usarlo nella barra di avanzamento di tqdm\n    test_dataset.name = folder_name \n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n    \n    # 2. Esegui la valutazione e salva i risultati\n    results = evaluate_model(model, test_loader, loss_bbox_fn, loss_plate_fn, device)\n    all_results[folder_name] = results\n    \n    # 3. Stampa i risultati per la categoria corrente\n    print(f\"Risultati per '{folder_name}':\")\n    for metric, value in results.items():\n        print(f\"  {metric}: {value:.4f}\")\n\n# --- Report Finale Aggregato ---\nprint(\"\\n--- Riepilogo dei Risultati del Test ---\")\n# Trasforma il dizionario dei risultati in un DataFrame di Pandas per una visualizzazione pulita\nresults_df = pd.DataFrame.from_dict(all_results, orient='index')\nprint(results_df.to_string())\nprint(\"---------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T09:21:29.977626Z","iopub.execute_input":"2025-07-17T09:21:29.978361Z","iopub.status.idle":"2025-07-17T09:22:49.142301Z","shell.execute_reply.started":"2025-07-17T09:21:29.978335Z","shell.execute_reply":"2025-07-17T09:22:49.141497Z"}},"outputs":[{"name":"stdout","text":"Caricamento del modello migliore per il test...\n\nAvvio del test su tutte le categorie...\n\n--- Valutazione della categoria: BASE ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on base]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7791d000b982467f80b6b98dd8b5ec3f"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'base':\n  Avg Loss: 0.1304\n  Char Acc (%): 97.1286\n  Seq Acc (%): 86.5000\n  IoU>0.7 (%): 100.0000\n\n--- Valutazione della categoria: BLUR ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on blur]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1aba78daa51482fb6cbfc1436be47cd"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'blur':\n  Avg Loss: 1.8037\n  Char Acc (%): 62.7857\n  Seq Acc (%): 8.8000\n  IoU>0.7 (%): 96.6000\n\n--- Valutazione della categoria: CHALLENGE ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on challenge]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafd95d5287b4e40bc25d1661a9aee1f"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'challenge':\n  Avg Loss: 1.8848\n  Char Acc (%): 62.3857\n  Seq Acc (%): 9.5000\n  IoU>0.7 (%): 96.7000\n\n--- Valutazione della categoria: DB ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on db]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9b4b0ad90cc45a8bdf392826f882209"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'db':\n  Avg Loss: 1.5847\n  Char Acc (%): 68.5714\n  Seq Acc (%): 17.4000\n  IoU>0.7 (%): 90.1000\n\n--- Valutazione della categoria: FN ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on fn]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bcbf451de814a2d81f29797de5b85ec"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'fn':\n  Avg Loss: 2.0130\n  Char Acc (%): 59.3143\n  Seq Acc (%): 13.5000\n  IoU>0.7 (%): 82.3000\n\n--- Valutazione della categoria: ROTATE ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on rotate]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95954e7a2b324a60928e3fb665c943ae"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'rotate':\n  Avg Loss: 1.3183\n  Char Acc (%): 72.5714\n  Seq Acc (%): 19.2000\n  IoU>0.7 (%): 91.3000\n\n--- Valutazione della categoria: TILT ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on tilt]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"512f89cce0454af2abba6c32ec238f82"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'tilt':\n  Avg Loss: 1.5011\n  Char Acc (%): 69.9143\n  Seq Acc (%): 11.8000\n  IoU>0.7 (%): 84.5000\n\n--- Valutazione della categoria: WEATHER ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Testing on weather]:   0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0975220d42c4ae3a587b0eb6fdc2ff5"}},"metadata":{}},{"name":"stdout","text":"Risultati per 'weather':\n  Avg Loss: 0.2236\n  Char Acc (%): 95.2000\n  Seq Acc (%): 77.6000\n  IoU>0.7 (%): 99.8000\n\n--- Riepilogo dei Risultati del Test ---\n           Avg Loss  Char Acc (%)  Seq Acc (%)  IoU>0.7 (%)\nbase       0.130354     97.128571         86.5        100.0\nblur       1.803670     62.785714          8.8         96.6\nchallenge  1.884791     62.385714          9.5         96.7\ndb         1.584730     68.571429         17.4         90.1\nfn         2.012973     59.314286         13.5         82.3\nrotate     1.318270     72.571429         19.2         91.3\ntilt       1.501129     69.914286         11.8         84.5\nweather    0.223628     95.200000         77.6         99.8\n---------------------------------------\n","output_type":"stream"}],"execution_count":64}]}