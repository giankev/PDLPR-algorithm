{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nThis notebook covers the training, testing, and evaluation of YOLOv5.\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **IMPORT**","metadata":{}},{"cell_type":"code","source":"import tarfile\nimport shutil\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport yaml\nimport os, torch\nfrom pathlib import Path\nfrom torchvision.ops import box_iou\nimport warnings\nimport sys, time, warnings, subprocess\nfrom kaggle_secrets import UserSecretsClient\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T10:56:19.906849Z","iopub.execute_input":"2025-07-15T10:56:19.907114Z","iopub.status.idle":"2025-07-15T10:56:28.239373Z","shell.execute_reply.started":"2025-07-15T10:56:19.907094Z","shell.execute_reply":"2025-07-15T10:56:28.238638Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **SETUP ENVIRONMENT**","metadata":{}},{"cell_type":"code","source":"#download the training datatset, and test dataset (dim(train) = 50k, dim(test) = 8k)\n!gdown --folder https://drive.google.com/drive/u/1/folders/1Qirh0lsjdsroLHEmJDtS6sVXPQKalW6j -O datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T10:56:43.347486Z","iopub.execute_input":"2025-07-15T10:56:43.347885Z","iopub.status.idle":"2025-07-15T10:57:31.153335Z","shell.execute_reply.started":"2025-07-15T10:56:43.347861Z","shell.execute_reply":"2025-07-15T10:57:31.152578Z"}},"outputs":[{"name":"stdout","text":"Retrieving folder contents\nProcessing file 1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X ccpd_test.tar\nProcessing file 1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_ ccpd_train.tar\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X\nFrom (redirected): https://drive.google.com/uc?id=1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X&confirm=t&uuid=25d4ea81-7951-4f03-9d78-3afe249bbd30\nTo: /kaggle/working/datasets/ccpd_test.tar\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557M/557M [00:07<00:00, 74.7MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_\nFrom (redirected): https://drive.google.com/uc?id=1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_&confirm=t&uuid=c5b3f0a2-c0f8-465b-b6cb-61f3a4b15eea\nTo: /kaggle/working/datasets/ccpd_train.tar\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.76G/3.76G [00:35<00:00, 107MB/s]\nDownload completed\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# extracting the .tar archive\ndef extract_tar_archive(archive_path, destination_path):\n\n    print(f\"Extracting the tar archive in:{archive_path}\")\n    with tarfile.open(archive_path, \"r\") as tar:\n        tar.extractall(path=destination_path)\n        \n    print(f\"Archive extracted in: {destination_path}\")\n\n#delete the .tar archive which now is useless\ndef delete_tar_archive(path_tar_archive):\n    \n    if os.path.exists(path_tar_archive):\n        shutil.rmtree(path_tar_archive)\n        print(f\"Folder eliminated: {path_tar_archive}\")\n    else:\n        print(f\"Folder not found: {path_tar_archive}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T10:58:01.342825Z","iopub.execute_input":"2025-07-15T10:58:01.343117Z","iopub.status.idle":"2025-07-15T10:58:01.349260Z","shell.execute_reply.started":"2025-07-15T10:58:01.343090Z","shell.execute_reply":"2025-07-15T10:58:01.348388Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"archive_path_train = \"/kaggle/working/datasets/ccpd_train.tar\"\narchive_path_test = \"/kaggle/working/datasets/ccpd_test.tar\"\nextract_path = \"/kaggle/working/\"\nfolder_path = \"/kaggle/working/ccpd_subset_base/train\"\n\n#when extracting the files, is important to eliminate the .tar archive which now occupy /kaggle/working space\nextract_tar_archive(archive_path_train, extract_path)\nextract_tar_archive(archive_path_test, extract_path)\ndelete_tar_archive(\"/kaggle/working/datasets/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T10:58:07.366467Z","iopub.execute_input":"2025-07-15T10:58:07.367170Z","iopub.status.idle":"2025-07-15T10:58:07.370484Z","shell.execute_reply.started":"2025-07-15T10:58:07.367143Z","shell.execute_reply":"2025-07-15T10:58:07.369872Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#cloning the yolov5 repo\n!git clone https://github.com/ultralytics/yolov5  \n%cd yolov5\n%pip install -qr requirements.txt  #dependencies\n%cd ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T10:58:27.807155Z","iopub.execute_input":"2025-07-15T10:58:27.807965Z","iopub.status.idle":"2025-07-15T10:59:56.303434Z","shell.execute_reply.started":"2025-07-15T10:58:27.807930Z","shell.execute_reply":"2025-07-15T10:59:56.302509Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 17516, done.\u001b[K\nremote: Counting objects: 100% (19/19), done.\u001b[K\nremote: Compressing objects: 100% (19/19), done.\u001b[K\nremote: Total 17516 (delta 6), reused 0 (delta 0), pack-reused 17497 (from 4)\u001b[K\nReceiving objects: 100% (17516/17516), 16.61 MiB | 32.95 MiB/s, done.\nResolving deltas: 100% (11994/11994), done.\n/kaggle/working/yolov5\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n/kaggle/working\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# download the pdlpr repo. github token required.\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"pddlr_token\")\n\nusername = \"giankev\"\nrepo_name = \"PDDLR-algorithm\"\n\ngit_url = f\"https://{username}:{token}@github.com/{username}/{repo_name}.git\"\n\nos.system(f\"git clone {git_url} /kaggle/working/{repo_name}\")\n%cd /kaggle/working/PDDLR-algorithm/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:00:18.577414Z","iopub.execute_input":"2025-07-15T11:00:18.577732Z","iopub.status.idle":"2025-07-15T11:00:22.539949Z","shell.execute_reply.started":"2025-07-15T11:00:18.577707Z","shell.execute_reply":"2025-07-15T11:00:22.539136Z"}},"outputs":[{"name":"stderr","text":"Cloning into '/kaggle/working/PDDLR-algorithm'...\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/working/PDDLR-algorithm\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#specify the path for train & val for yolov5\nCONTENT = {\n    'train': '/kaggle/working/ccpd_yolo_dataset/images/train',\n    'val': '/kaggle/working/ccpd_yolo_dataset/images/val',\n    'nc': 1,\n    'names': ['plate']\n}\n\nccpd_path = \"yolov5/ccpd.yaml\"   \nos.makedirs(os.path.dirname(ccpd_path), exist_ok=True)\n\n#write the .yaml file in /kaggle/working/yolov5/ccpd.yaml\nwith open(ccpd_path, 'w') as f:\n    yaml.dump(CONTENT, f, sort_keys=False)\n\nprint(f\"file added in: {os.getcwd()}/{ccpd_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:00:25.918545Z","iopub.execute_input":"2025-07-15T11:00:25.918853Z","iopub.status.idle":"2025-07-15T11:00:25.922729Z","shell.execute_reply.started":"2025-07-15T11:00:25.918831Z","shell.execute_reply":"2025-07-15T11:00:25.922123Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## **GLOBALS**","metadata":{}},{"cell_type":"code","source":"# define the alphabet used for plate decoding.\n# each LP number is comprised of a Chinese character, a letter, and five letters or numbers.\n\nPROVINCES = [\"Áöñ\", \"Ê≤™\", \"Ê¥•\", \"Ê∏ù\", \"ÂÜÄ\", \"Êôã\", \"Ëíô\", \"ËæΩ\", \"Âêâ\", \"Èªë\",\n             \"Ëãè\", \"Êµô\", \"‰∫¨\", \"ÈóΩ\", \"Ëµ£\", \"È≤Å\", \"Ë±´\", \"ÈÑÇ\", \"Êπò\", \"Á≤§\",\n             \"Ê°Ç\", \"Áêº\", \"Â∑ù\", \"Ë¥µ\", \"‰∫ë\", \"Ëóè\", \"Èôï\", \"Áîò\", \"Èùí\", \"ÂÆÅ\",\n             \"Êñ∞\", \"Ë≠¶\", \"Â≠¶\", \"O\"]\n\nALPHA = ['A','B','C','D','E','F','G','H','J','K',\n             'L','M','N','P','Q','R','S','T','U','V',\n             'W','X','Y','Z','O'] \n\nADS = ['A','B','C','D','E','F','G','H','J','K',\n       'L','M','N','P','Q','R','S','T','U','V',\n       'W','X','Y','Z','0','1','2','3','4','5',\n       '6','7','8','9','O']\n\nSRC_IMG_DIR = \"/kaggle/working/ccpd_subset_base/train\"\nOUT_BASE = \"/kaggle/working/ccpd_yolo_dataset\"\nIMG_W, IMG_H = 720, 1160\nCLASS_ID = 0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **FUNCTION**","metadata":{}},{"cell_type":"code","source":"#extracting the metadata from each img in this format (image_path,x1_bbox,y1_bbox,x2_bbox,y2_bbox,plate_number)\ndef decode_plate(s):\n    \"this method is used for decoding the plate starting from the name of .jpg file\"\n    idx   = list(map(int, s.split(\"_\")))\n    try:\n        return PROVINCES[idx[0]] + ALPHA[idx[1]] + \"\".join(ADS[i] for i in idx[2:])\n    except Exception:\n        return None\n\n\ndef split_bbox(bbox_str):\n    \"extracting x1,y1,x2,y2, ex. '283___502_511___591'  ‚Üí  ['283','502','511','591']\"\n    tokens = []\n    for seg in bbox_str.split(\"___\"):\n        tokens.extend(seg.split(\"_\"))\n    if len(tokens) == 4 and all(t.isdigit() for t in tokens):\n        return map(int, tokens)\n    return (None,)*4\n\nfolder = \"/kaggle/working/ccpd_subset_base/train\"\nrows   = []\n\nfor fname in os.listdir(folder):\n    if not fname.endswith(\".jpg\"): continue\n\n    parts = fname[:-4].split(\"-\")           \n    if len(parts) < 6:\n        continue #the ccpd file name is wrong           \n\n    x1,y1,x2,y2 = split_bbox(parts[2])      \n    plate = decode_plate(parts[4])    \n\n    rows.append({\n        \"image_path\": os.path.join(folder, fname),\n        \"x1_bbox\": x1, \"y1_bbox\": y1,\n        \"x2_bbox\": x2, \"y2_bbox\": y2,\n        \"plate_number\": plate\n    })\n\ndf = pd.DataFrame(rows)\n\"\"\"print(\"Rows number:\", len(df))         \nprint(\"Columns numner:\", df.shape[1])\nprint(\"Shape:\", df.shape)\ndf.head()\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def export_yolo(df_split, split_name, img_w, img_h):\n    \"\"\"\n    This method is used for creating the dataset for yolov5.\n    Input: df_split (dataframe created by preovious method), split_name (train, val or test)\n    For each img we need to create .txt file, which contains:\n    CLASS_ID, x_center (normalized), y_center (normalized), width, height.\n    The file is created on the directory \"/kaggle/working/ccpd_yolo_dataset\" (OUT_BASE) \n    \"\"\"\n    img_dir = os.path.join(OUT_BASE, \"images\", split_name)\n    lbl_dir = os.path.join(OUT_BASE, \"labels\", split_name)\n    os.makedirs(img_dir, exist_ok=True)\n    os.makedirs(lbl_dir, exist_ok=True)\n\n    for _, row in df_split.iterrows():\n        try:\n            x_center = (row[\"x1_bbox\"] + row[\"x2_bbox\"]) / 2 / img_w\n            y_center = (row[\"y1_bbox\"] + row[\"y2_bbox\"]) / 2 / img_h\n            width = (row[\"x2_bbox\"] - row[\"x1_bbox\"]) / img_w\n            height = (row[\"y2_bbox\"] - row[\"y1_bbox\"]) / img_h\n\n            yolo_line = f\"{CLASS_ID} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n\n            base_name = os.path.basename(row[\"image_path\"])\n            name_no_ext = os.path.splitext(base_name)[0]\n\n            dst_img_path = os.path.join(img_dir, base_name)\n            shutil.copy2(row[\"image_path\"], dst_img_path)\n\n            #label YOLO\n            label_path = os.path.join(lbl_dir, f\"{name_no_ext}.txt\")\n            with open(label_path, \"w\") as f:\n                f.write(yolo_line)\n\n        except Exception as e:\n            print(f\"Errore su file {row['image_path']}: {e}\")\n\n    print(f\"{split_name.upper()} completato  {len(df_split)} esempi\")\n\n# for the two split\nexport_yolo(df_train, \"train\", IMG_W, IMG_H)\nexport_yolo(df_val, \"val\", IMG_W, IMG_H)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **TRAINING PHASE**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nThe training phase consists of two phase:\nFirst we train the model for 5 epochs with --freeze parameter set to 10, and initial lr 0.001,\nthen we start another train with 40 epochs, and adjusting the lr to 0.0005.\nData augmentation techniques such as color and geometric distortions are specified\nin the corresponding .yaml configuration files..\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#we split the dataset in 80/20 for training phase.\ndf_train, df_val = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n\nprint(f\"Train set: {len(df_train)} img\")\nprint(f\"Val set:   {len(df_val)} img\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_hyp = {\n    'lr0': 0.001,        # Initial learning-rate (fine-tuning)\n    'lrf': 0.10,          # lr_final = lr0 * lrf  (cosine scheduler)\n    'momentum': 0.937,\n    'weight_decay': 0.0002,\n\n    # warm-up\n    'warmup_epochs': 3.0,\n    'warmup_momentum': 0.8,\n    'warmup_bias_lr': 0.1,\n\n    # loss balance\n    'box': 0.05,\n    'cls': 0.20,         \n    'cls_pw': 1.0,\n    'obj': 0.90,\n    'obj_pw': 1.0,\n    'iou_t': 0.20,\n    'anchor_t': 4.0,\n    'fl_gamma': 0.0,\n\n    # augmentation - color / geometry\n    'hsv_h': 0.15,\n    'hsv_s': 0.50,\n    'hsv_v': 0.8,\n\n    'degrees': 7.5,\n    'translate': 0.10,\n    'scale': 0.40,\n    'shear': 5.0,\n    'perspective': 0.0,\n\n    # flip & mix\n    'flipud': 0.0,\n    'fliplr': 0.0,\n\n    'mosaic': 0.0,\n    'mixup': 0.0,\n    'copy_paste': 0.20\n}\n\nhyp_path = \"yolov5/data/hyps/my_ccpd.yaml\"   \nos.makedirs(os.path.dirname(hyp_path), exist_ok=True)\n\nwith open(hyp_path, 'w') as f:\n    yaml.dump(my_hyp, f, sort_keys=False)\n\nprint(f\"file added in: {os.getcwd()}/{hyp_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#training phase A with --freeze set to 10.\n!wandb disabled\n!python  -W ignore yolov5/train.py \\\n  --weights yolov5s.pt \\\n  --data yolov5/ccpd.yaml \\\n  --hyp yolov5/data/hyps/my_ccpd.yaml \\\n  --batch 32 \\\n  --epochs 5 \\\n  --freeze 10 \\\n  --name ccpd_ftA \\\n  --cache","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_hyp = {\n    'lr0': 0.0005,        # Initial learning-rate (fine-tuning)\n    'lrf': 0.10,          # lr_final = lr0 * lrf  (cosine scheduler)\n    'momentum': 0.937,\n    'weight_decay': 0.0002,\n\n    # warm-up\n    'warmup_epochs': 3.0,\n    'warmup_momentum': 0.8,\n    'warmup_bias_lr': 0.1,\n\n    # loss balance\n    'box': 0.05,\n    'cls': 0.20,         \n    'cls_pw': 1.0,\n    'obj': 0.90,\n    'obj_pw': 1.0,\n    'iou_t': 0.20,\n    'anchor_t': 4.0,\n    'fl_gamma': 0.0,\n\n    # augmentation - color / geometry\n    'hsv_h': 0.15,\n    'hsv_s': 0.50,\n    'hsv_v': 0.8,\n\n    'degrees': 7.5,\n    'translate': 0.10,\n    'scale': 0.40,\n    'shear': 5.0,\n    'perspective': 0.0,\n\n    # flip & mix\n    'flipud': 0.0,\n    'fliplr': 0.0,\n\n    'mosaic': 1.0,\n    'mixup': 0.0,\n    'copy_paste': 0.20\n}\n\nhyp_path = \"yolov5/data/hyps/my_ccpd_B.yaml\"   \nos.makedirs(os.path.dirname(hyp_path), exist_ok=True)\n\nwith open(hyp_path, 'w') as f:\n    yaml.dump(my_hyp, f, sort_keys=False)\n\nprint(f\"file added in: {os.getcwd()}/{hyp_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#UNFREEZE (phase-B)\n!wandb disabled\n!stdbuf -oL -eL python -u -W ignore yolov5/train.py \\\n  --weights /kaggle/input/weights-train-a/best_A.pt \\\n  --data  yolov5/ccpd.yaml \\\n  --hyp   yolov5/data/hyps/my_ccpd_B.yaml \\\n  --batch 32 \\\n  --epochs 40  \\\n  --name  ccpd_ftB \\\n  --cache","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **TEST PHASE**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nWe test yolov5 in each dataset folder: base, blur, db, fn, tilt, rotate, challenge, weather. \n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"folder = \"/kaggle/working/ccpd_test\"\nrows = []\n\nfor root, _, files in os.walk(folder):\n    for fname in files:\n        if not fname.endswith(\".jpg\"):\n            continue\n\n        parts = fname[:-4].split(\"-\")\n        if len(parts) < 6:\n            continue\n\n        x1, y1, x2, y2 = split_bbox(parts[2])\n        plate = decode_plate(parts[4])\n        full_path = os.path.join(root, fname)\n\n        rows.append({\n            \"image_path\": full_path,\n            \"x1_bbox\": x1,\n            \"y1_bbox\": y1,\n            \"x2_bbox\": x2,\n            \"y2_bbox\": y2,\n            \"plate_number\": plate\n        })\n\ndf = pd.DataFrame(rows)\nprint(f\"Dataset created: {len(df)} rows\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:00:43.303972Z","iopub.execute_input":"2025-07-15T11:00:43.304250Z","iopub.status.idle":"2025-07-15T11:00:43.413894Z","shell.execute_reply.started":"2025-07-15T11:00:43.304230Z","shell.execute_reply":"2025-07-15T11:00:43.413179Z"}},"outputs":[{"name":"stdout","text":"Dataset creato con 8000 righe\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                          image_path  x1_bbox  y1_bbox  \\\n0  /kaggle/working/ccpd_test/db/0170-0_2-179___45...      179      456   \n1  /kaggle/working/ccpd_test/db/0362-1_0-349___44...      349      441   \n2  /kaggle/working/ccpd_test/db/0643-9_23-147___4...      147      487   \n3  /kaggle/working/ccpd_test/db/0564-4_0-91___470...       91      470   \n4  /kaggle/working/ccpd_test/db/0148-0_0-216___47...      216      478   \n\n   x2_bbox  y2_bbox plate_number  \n0      383      526      ÁöñAS2Y56  \n1      635      547      ÁöñKXM166  \n2      503      638      ÁöñA136Z9  \n3      423      612      ÁöñAZZ902  \n4      407      543      ÁöñACD991  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>x1_bbox</th>\n      <th>y1_bbox</th>\n      <th>x2_bbox</th>\n      <th>y2_bbox</th>\n      <th>plate_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/ccpd_test/db/0170-0_2-179___45...</td>\n      <td>179</td>\n      <td>456</td>\n      <td>383</td>\n      <td>526</td>\n      <td>ÁöñAS2Y56</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/ccpd_test/db/0362-1_0-349___44...</td>\n      <td>349</td>\n      <td>441</td>\n      <td>635</td>\n      <td>547</td>\n      <td>ÁöñKXM166</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/ccpd_test/db/0643-9_23-147___4...</td>\n      <td>147</td>\n      <td>487</td>\n      <td>503</td>\n      <td>638</td>\n      <td>ÁöñA136Z9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/ccpd_test/db/0564-4_0-91___470...</td>\n      <td>91</td>\n      <td>470</td>\n      <td>423</td>\n      <td>612</td>\n      <td>ÁöñAZZ902</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/ccpd_test/db/0148-0_0-216___47...</td>\n      <td>216</td>\n      <td>478</td>\n      <td>407</td>\n      <td>543</td>\n      <td>ÁöñACD991</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"#export_yolo now consider each subfolder for creating the dataset\ndef export_yolo(df_split, split_name, img_w, img_h):\n    base_img_dir = os.path.join(OUT_BASE, \"images\", split_name)\n    base_lbl_dir = os.path.join(OUT_BASE, \"labels\", split_name)\n\n    count = 0\n\n    for _, row in df_split.iterrows():\n        try:\n            if None in (row[\"x1_bbox\"], row[\"y1_bbox\"], row[\"x2_bbox\"], row[\"y2_bbox\"]):\n                continue\n       \n            x_center = (row[\"x1_bbox\"] + row[\"x2_bbox\"]) / 2 / img_w\n            y_center = (row[\"y1_bbox\"] + row[\"y2_bbox\"]) / 2 / img_h\n            width    = (row[\"x2_bbox\"] - row[\"x1_bbox\"]) / img_w\n            height   = (row[\"y2_bbox\"] - row[\"y1_bbox\"]) / img_h\n\n            yolo_line = f\"{CLASS_ID} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n\n            img_path = row[\"image_path\"]\n            base_name = os.path.basename(img_path)\n            name_no_ext = os.path.splitext(base_name)[0]\n\n            rel_subfolder = os.path.basename(os.path.dirname(img_path))\n\n            img_dir = os.path.join(base_img_dir, rel_subfolder)\n            lbl_dir = os.path.join(base_lbl_dir, rel_subfolder)\n            os.makedirs(img_dir, exist_ok=True)\n            os.makedirs(lbl_dir, exist_ok=True)\n\n            dst_img_path = os.path.join(img_dir, base_name)\n            shutil.copy2(img_path, dst_img_path)\n\n            label_path = os.path.join(lbl_dir, f\"{name_no_ext}.txt\")\n            with open(label_path, \"w\") as f:\n                f.write(yolo_line)\n\n            count += 1\n\n        except Exception as e:\n            print(f\"Error {row['image_path']}: {e}\")\n\n    print(f\"{split_name.upper()} compleated: {count} examples saved.\")\n    \nexport_yolo(df, \"test\", IMG_W, IMG_H)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:00:48.042807Z","iopub.execute_input":"2025-07-15T11:00:48.043078Z","iopub.status.idle":"2025-07-15T11:00:48.051089Z","shell.execute_reply.started":"2025-07-15T11:00:48.043057Z","shell.execute_reply":"2025-07-15T11:00:48.050487Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"base_dir = \"/kaggle/working/ccpd_yolo_dataset\"\nimg_root = os.path.join(base_dir, \"images\", \"test\")\nlbl_root = os.path.join(base_dir, \"labels\", \"test\")\ntemplate_yaml_path = \"/kaggle/working/yolov5/ccpd_temp.yaml\"\nweights_path = \"/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt\"\n\n# All subdir (tilt, blur, ..)\nsubdirs = [d for d in os.listdir(img_root) if os.path.isdir(os.path.join(img_root, d))]\n\nfor sub in subdirs:\n    img_dir = os.path.join(\"images/test\", sub)  \n    lbl_dir = os.path.join(\"labels/test\", sub)\n\n    yaml_content = f\"\"\"\\\n                    path: {base_dir}\n                    train: {img_dir}  # not used\n                    val: {img_dir}\n                    nc: 1\n                    names: ['plate']\n                    \"\"\"\n    with open(template_yaml_path, \"w\") as f:\n        f.write(yaml_content)\n\n    print(f\" Subset: {sub}\")\n    !python /kaggle/working/yolov5/val.py \\\n    --weights \"{weights_path}\" \\\n    --data    {template_yaml_path} \\\n    --imgsz   640 \\\n    --task    val \\\n    --iou-thres 0.7 \\\n    --conf-thres 0.001 \\\n    --save-txt --save-conf \\\n    --name   test_{sub} \\\n    --project /kaggle/working/yolov5/runs/test \\\n    --exist-ok","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T20:25:50.341148Z","iopub.execute_input":"2025-07-14T20:25:50.341475Z","iopub.status.idle":"2025-07-14T20:28:39.323630Z","shell.execute_reply.started":"2025-07-14T20:25:50.341451Z","shell.execute_reply":"2025-07-14T20:28:39.322830Z"}},"outputs":[{"name":"stdout","text":" Valutazione subset: db\nCreating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_db, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 23.5MB/s]\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/db... 1000 images, 0\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/db.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.959      0.942      0.958       0.51\nSpeed: 0.1ms pre-process, 2.4ms inference, 1.8ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_db\u001b[0m\n999 labels saved to /kaggle/working/yolov5/runs/test/test_db/labels\n Valutazione subset: rotate\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_rotate, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/rotate... 1000 image\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/rotate.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.991      0.992      0.993      0.686\nSpeed: 0.1ms pre-process, 2.2ms inference, 1.7ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_rotate\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_rotate/labels\n Valutazione subset: challenge\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_challenge, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/challenge... 1000 im\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/challenge.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.993      0.996      0.994      0.664\nSpeed: 0.1ms pre-process, 2.4ms inference, 1.3ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_challenge\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_challenge/labels\n Valutazione subset: tilt\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_tilt, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/tilt... 1000 images,\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/tilt.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.992      0.993      0.995       0.62\nSpeed: 0.1ms pre-process, 2.3ms inference, 1.5ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_tilt\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_tilt/labels\n Valutazione subset: blur\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_blur, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/blur... 1000 images,\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/blur.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.988      0.978      0.987      0.611\nSpeed: 0.1ms pre-process, 2.3ms inference, 1.3ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_blur\u001b[0m\n998 labels saved to /kaggle/working/yolov5/runs/test/test_blur/labels\n Valutazione subset: fn\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_fn, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/fn... 1000 images, 0\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/fn.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.976      0.975      0.971      0.587\nSpeed: 0.2ms pre-process, 2.3ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_fn\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_fn/labels\n Valutazione subset: base\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_base, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/base... 1000 images,\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/base.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.997          1      0.995      0.753\nSpeed: 0.2ms pre-process, 2.3ms inference, 1.5ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_base\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_base/labels\n Valutazione subset: weather\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_weather, exist_ok=True, half=False, dnn=False\nYOLOv5 üöÄ v7.0-422-g2540fd4c Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/weather... 1000 imag\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/test/weather.cache\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.999          1      0.994       0.78\nSpeed: 0.2ms pre-process, 2.3ms inference, 1.6ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_weather\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_weather/labels\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#!zip -r ccpd_results.zip /kaggle/working/yolov5/runs/test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **METRIC COMPUTATION**","metadata":{}},{"cell_type":"code","source":"\"\"\"\nWe compute several metrics such as: Recall_IoU>0.7,  Precision_IoU>0.7,  Accuracy_img_IoU>0.7, FPS.\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_dir  = \"/kaggle/working/ccpd_yolo_dataset\"\nruns_root = \"/kaggle/working/yolov5/runs/test\"\n\nsubdirs = [\n    d for d in os.listdir(os.path.join(base_dir, \"images\", \"test\"))\n    if os.path.isdir(os.path.join(base_dir, \"images\", \"test\", d))\n]\n\n\ndef yolo_to_xyxy(xc, yc, w, h):\n    return [xc - w/2, yc - h/2, xc + w/2, yc + h/2]\n\ndef load_boxes(txt_path):\n    if not txt_path.exists():\n        return torch.empty((0, 4))\n    boxes = []\n    for line in txt_path.read_text().strip().splitlines():\n        _, xc, yc, w, h, *rest = map(float, line.split())\n        boxes.append(yolo_to_xyxy(xc, yc, w, h))\n    return torch.tensor(boxes) if boxes else torch.empty((0, 4))\n\ndef metrics_one_subset(sub, thr=0.7):\n    pred_dir = Path(runs_root) / f\"test_{sub}\" / \"labels\"\n    gt_dir   = Path(base_dir)   / \"labels\" / \"test\" / sub\n\n    tp, fp, total_gt, correct_img = 0, 0, 0, 0   \n\n    for gt_file in gt_dir.glob(\"*.txt\"):\n        gt_boxes   = load_boxes(gt_file)               \n        pred_boxes = load_boxes(pred_dir / gt_file.name)\n        total_gt  += len(gt_boxes)                     \n\n        # accuracy\n        if len(gt_boxes) and len(pred_boxes):\n            if (box_iou(gt_boxes, pred_boxes).max() >= thr):\n                correct_img += 1\n                \n        # TP / FP box \n        if len(gt_boxes) and len(pred_boxes):\n            ious = box_iou(gt_boxes, pred_boxes)\n            tp  += (ious.max(dim=1).values > thr).sum().item()\n            fp  += (ious.max(dim=0).values <= thr).sum().item()\n        elif len(pred_boxes):  \n            fp += len(pred_boxes)\n\n    fn = total_gt - tp\n    recall    = tp / total_gt if total_gt else 0.0\n    precision = tp / (tp + fp) if (tp + fp) else 0.0\n    accuracy  = correct_img / total_gt if total_gt else 0.0 \n\n    return {\n        \"subset\": sub,\n        \"GT\": total_gt,\n        \"TP\": tp,\n        \"FP\": fp,\n        \"FN\": fn,\n        \"Recall_IoU>0.7\":    round(recall,    4),\n        \"Precision_IoU>0.7\": round(precision, 4),\n        \"Accuracy_img_IoU>0.7\": round(accuracy, 4)\n    }\n\nresults = [metrics_one_subset(sub) for sub in subdirs]\ndf = pd.DataFrame(results)\n\ndf = df[[\"subset\", \"GT\", \"TP\", \"FP\", \"FN\",\n         \"Recall_IoU>0.7\", \"Precision_IoU>0.7\", \"Accuracy_img_IoU>0.7\"]]\n\nprint(df.to_string(index=False))\ndf.to_csv(\"/kaggle/working/iou0.7_metrics_with_accuracy.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T21:17:08.832530Z","iopub.execute_input":"2025-07-14T21:17:08.833234Z","iopub.status.idle":"2025-07-14T21:17:13.677097Z","shell.execute_reply.started":"2025-07-14T21:17:08.833206Z","shell.execute_reply":"2025-07-14T21:17:13.676276Z"}},"outputs":[{"name":"stdout","text":"   subset   GT   TP   FP  FN  Recall_IoU>0.7  Precision_IoU>0.7  Accuracy_img_IoU>0.7\n       db 1000  936 1085  64           0.936             0.4631                 0.936\n   rotate 1000  990  655  10           0.990             0.6018                 0.990\nchallenge 1000  992 1075   8           0.992             0.4799                 0.992\n     tilt 1000  980  804  20           0.980             0.5493                 0.980\n     blur 1000  972 1034  28           0.972             0.4845                 0.972\n       fn 1000  971 1472  29           0.971             0.3975                 0.971\n     base 1000 1000  565   0           1.000             0.6390                 1.000\n  weather 1000  999  530   1           0.999             0.6534                 0.999\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"base_dir      = \"/kaggle/working/ccpd_yolo_dataset\"\nimg_dir_rel   = \"images/test\"                 \ntemplate_yaml = \"/kaggle/working/yolov5/ccpd_temp.yaml\"\nweights_path  = \"/kaggle/working/PDDLR-algorithm/scr/yolov5/best.pt\"\nbatch_size    = 5 # the paper use batch size 5 for fps computation\n\nyaml_text = f\"\"\"\\\npath: {base_dir}\ntrain: {img_dir_rel}  # not used\nval:   {img_dir_rel}\nnc: 1\nnames: ['plate']\n\"\"\"\nwith open(template_yaml, \"w\") as f:\n    f.write(yaml_text)\n\ndef count_imgs(root):                \n    exts = {\".jpg\", \".jpeg\"}\n    return sum(1 for p in Path(root).rglob('*') if p.suffix.lower() in exts)\n\nn_imgs = count_imgs(Path(base_dir) / img_dir_rel)\nif n_imgs == 0:\n    raise RuntimeError(\"Error: No img found\")\n\nprint(f\"Starting clock for {n_imgs} imgs (batch={batch_size})\")\n\nt0 = time.perf_counter() #clock starting\n\ncmd = [\n    sys.executable, \"-W\", \"ignore\",                  \n    \"/kaggle/working/yolov5/val.py\",\n    \"--weights\", weights_path,\n    \"--data\",    template_yaml,\n    \"--imgsz\",   \"640\",\n    \"--batch\",   str(batch_size),\n    \"--task\",    \"val\",\n    \"--iou-thres\",\"0.7\",\n    \"--conf-thres\",\"0.001\",\n    \"--name\",    \"ccpd_global\",\n    \"--project\", \"/kaggle/working/yolov5/runs/test\",\n    \"--exist-ok\"\n]\nresult = subprocess.run(cmd, capture_output=True, text=True)\nt1 = time.perf_counter() #stop counter\n\n#\nelapsed = t1 - t0            # total seconds\nfps     = n_imgs / elapsed   # fps computation\n\nprint(f\"Total img   : {n_imgs}\")\nprint(\"Formula              : FPS = num_images / elapsed_seconds\")\nprint(f\"Computation              : {n_imgs} / {elapsed:.2f} s  =  {fps:,.1f} FPS\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T11:33:25.214502Z","iopub.execute_input":"2025-07-15T11:33:25.215123Z","iopub.status.idle":"2025-07-15T11:34:47.888131Z","shell.execute_reply.started":"2025-07-15T11:33:25.215099Z","shell.execute_reply":"2025-07-15T11:34:47.887495Z"}},"outputs":[{"name":"stdout","text":"‚û°Ô∏è  Inizio validazione unica su 8000 immagini (batch=5) ‚Ä¶\n\n=== RISULTATO GLOBALE ===\nImmagini elaborate   : 8000\nFormula              : FPS = num_images / elapsed_seconds\nCalcolo              : 8000 / 82.42 s  =  97.1 FPS\n","output_type":"stream"}],"execution_count":21}]}