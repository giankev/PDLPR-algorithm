{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12477531,"sourceType":"datasetVersion","datasetId":7872655}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"working_on_kaggle = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:07:15.236566Z","iopub.execute_input":"2025-07-15T12:07:15.237239Z","iopub.status.idle":"2025-07-15T12:07:15.243436Z","shell.execute_reply.started":"2025-07-15T12:07:15.237215Z","shell.execute_reply":"2025-07-15T12:07:15.242727Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"if working_on_kaggle:\n    !pip install --quiet gdown\n    !apt-get install -y fonts-noto-cjk > /dev/null\n\n    import os\n    from kaggle_secrets import UserSecretsClient\n\n    # Recupera il token in modo sicuro\n    user_secrets = UserSecretsClient()\n    token = user_secrets.get_secret(\"pddlr_token\")\n\n    # Dati GitHub\n    username = \"giankev\"\n    repo_name = \"PDDLR-algorithm\"\n\n    # URL di clonazione con autenticazione via token\n    git_url = f\"https://{username}:{token}@github.com/{username}/{repo_name}.git\"\n\n    # Clonazione\n    os.system(f\"git clone --branch novelty {git_url} /kaggle/working/{repo_name}\")\n    %cd /kaggle/working/PDDLR-algorithm/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:07:15.244912Z","iopub.execute_input":"2025-07-15T12:07:15.245094Z","iopub.status.idle":"2025-07-15T12:07:15.262002Z","shell.execute_reply.started":"2025-07-15T12:07:15.245078Z","shell.execute_reply":"2025-07-15T12:07:15.261234Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport tarfile\nimport shutil\nimport random\nimport math\nimport warnings\nimport gdown\nimport cv2\n\nimport numpy as np\nimport pandas as pd\nimport yaml\nfrom PIL import Image, ImageDraw, ImageFilter\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset \nimport torchvision.transforms as T\nfrom torchvision.models import mobilenet_v3_small\nimport torchvision.transforms.functional as TF\nfrom torchvision.transforms.functional import to_pil_image\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:07:15.262812Z","iopub.execute_input":"2025-07-15T12:07:15.263056Z","iopub.status.idle":"2025-07-15T12:07:24.172569Z","shell.execute_reply.started":"2025-07-15T12:07:15.263034Z","shell.execute_reply":"2025-07-15T12:07:24.171950Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Globals","metadata":{}},{"cell_type":"code","source":"NUM_WORKERS = 2\nSEED = 42\nBATCH_SIZE = 128\nVAL_SPLIT_SIZE = 0.2\nEPOCHS = 10\nNUM_SAMPLES = 200\n\narchive_path_train = \"/kaggle/working/datasets/ccpd_train.tar\"\narchive_path_test = \"/kaggle/working/datasets/ccpd_test.tar\"\nextract_path = \"/kaggle/working\"\nfolder_path = \"/kaggle/working/ccpd_subset_base/train\"\nsubfolders = [\"base\", \"blur\", \"challenge\", \"db\", \"fn\", \"rotate\", \"tilt\", \"weather\"]\n\nPROVINCES = [\"Áöñ\", \"Ê≤™\", \"Ê¥•\", \"Ê∏ù\", \"ÂÜÄ\", \"Êôã\", \"Ëíô\", \"ËæΩ\", \"Âêâ\", \"Èªë\",\"Ëãè\", \"Êµô\", \"‰∫¨\", \"ÈóΩ\", \"Ëµ£\", \"È≤Å\", \"Ë±´\", \"ÈÑÇ\", \"Êπò\", \"Á≤§\", \"Ê°Ç\", \"Áêº\", \"Â∑ù\", \"Ë¥µ\", \"‰∫ë\", \"Ëóè\", \"Èôï\", \"Áîò\", \"Èùí\", \"ÂÆÅ\", \"Êñ∞\", \"Ë≠¶\", \"Â≠¶\", \"O\"]\n\nALPHA = ['A','B','C','D','E','F','G','H','J','K', 'L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z','O']\n\nADS = ['A','B','C','D','E','F','G','H','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9','O']\n\nIMG_TARGET_SIZE = (224, 224)\nMEAN, STD = (0.485,0.456,0.406), (0.229,0.224,0.225)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:10:17.532218Z","iopub.execute_input":"2025-07-15T13:10:17.532520Z","iopub.status.idle":"2025-07-15T13:10:17.539090Z","shell.execute_reply.started":"2025-07-15T13:10:17.532499Z","shell.execute_reply":"2025-07-15T13:10:17.538331Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"def extract_tar_archive(archive_path, destination_path):\n\n    print(f\"Extracting the tar archive in:{archive_path}\")\n    with tarfile.open(archive_path, \"r\") as tar:\n        tar.extractall(path=destination_path)\n\n    print(f\"Archive extracted in: {destination_path}\")\n\ndef delete_tar_archive(path_tar_archive):\n\n    if os.path.exists(path_tar_archive):\n        shutil.rmtree(path_tar_archive)\n        print(f\"Folder eliminated: {path_tar_archive}\")\n    else:\n        print(f\"Folder not found: {path_tar_archive}\")\n\ndef set_seed(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    \ndef decode_plate(s):\n    idx   = list(map(int, s.split(\"_\")))\n    try:\n        return PROVINCES[idx[0]] + ALPHA[idx[1]] + \"\".join(ADS[i] for i in idx[2:])\n    except Exception:\n        return None\n\ndef split_bbox(bbox_str):\n    coords = bbox_str.replace('___', '_').split('_')\n    return tuple(map(int, coords))\n    \ndef create_dataframe(folder_path, char2idx):\n    all_files = sorted(os.listdir(folder_path))\n    jpg_files = [f for f in all_files if f.endswith('.jpg')]\n\n    rows = []\n    for fname in jpg_files:\n        parts = fname[:-4].split(\"-\")\n        if len(parts) < 6:\n            continue\n\n        try:\n            x1, y1, x2, y2 = split_bbox(parts[2])\n            plate = decode_plate(parts[4])\n            label = encode_plate(plate, char2idx)\n        except Exception as e:\n            print(f\"Errore con file {fname}: {e}\")\n            continue\n\n        rows.append({\n            \"image_path\": os.path.join(folder_path, fname),\n            \"x1_bbox\": x1, \"y1_bbox\": y1,\n            \"x2_bbox\": x2, \"y2_bbox\": y2,\n            \"plate_number\": plate,\n            \"label\": label\n        })\n\n    return pd.DataFrame(rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:06:28.774803Z","iopub.execute_input":"2025-07-15T13:06:28.775080Z","iopub.status.idle":"2025-07-15T13:06:28.784024Z","shell.execute_reply.started":"2025-07-15T13:06:28.775059Z","shell.execute_reply":"2025-07-15T13:06:28.783190Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"## Download and extraction\n","metadata":{}},{"cell_type":"code","source":"!gdown --folder https://drive.google.com/drive/folders/143HxhUrqkFIdfCzZQ3dA4Mqt8cjARCxx -O datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:07:24.319993Z","iopub.execute_input":"2025-07-15T12:07:24.320235Z","iopub.status.idle":"2025-07-15T12:08:03.811589Z","shell.execute_reply.started":"2025-07-15T12:07:24.320209Z","shell.execute_reply":"2025-07-15T12:08:03.810857Z"}},"outputs":[{"name":"stdout","text":"Retrieving folder contents\nProcessing file 1hqZnTIOaRIaPPfN-juQKADCnE4ZJqqtO ccpd_train.tar\nProcessing file 1rlOc7X2_C9vq2sm1ULBjNAgb_gy6CP8R ccpd_test.tar\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1hqZnTIOaRIaPPfN-juQKADCnE4ZJqqtO\nFrom (redirected): https://drive.google.com/uc?id=1hqZnTIOaRIaPPfN-juQKADCnE4ZJqqtO&confirm=t&uuid=4dba2a78-52cc-4725-afee-f8467abbbfab\nTo: /kaggle/working/datasets/ccpd_train.tar\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.76G/3.76G [00:31<00:00, 118MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1rlOc7X2_C9vq2sm1ULBjNAgb_gy6CP8R\nFrom (redirected): https://drive.google.com/uc?id=1rlOc7X2_C9vq2sm1ULBjNAgb_gy6CP8R&confirm=t&uuid=e7123347-a599-41e5-8a96-8c6790694dab\nTo: /kaggle/working/datasets/ccpd_test.tar\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557M/557M [00:03<00:00, 168MB/s]\nDownload completed\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"set_seed(SEED)\nextract_tar_archive(archive_path_train, extract_path)\nextract_tar_archive(archive_path_test, extract_path)\ndelete_tar_archive(\"/kaggle/working/datasets\")\nnum_files = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n\nprint(f\" Number of images in '{folder_path}': {num_files}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:08:03.812641Z","iopub.execute_input":"2025-07-15T12:08:03.812932Z","iopub.status.idle":"2025-07-15T12:08:20.517143Z","shell.execute_reply.started":"2025-07-15T12:08:03.812897Z","shell.execute_reply":"2025-07-15T12:08:20.516573Z"}},"outputs":[{"name":"stdout","text":"Extracting the tar archive in:/kaggle/working/datasets/ccpd_train.tar\nArchive extracted in: /kaggle/working\nExtracting the tar archive in:/kaggle/working/datasets/ccpd_test.tar\nArchive extracted in: /kaggle/working\nFolder eliminated: /kaggle/working/datasets\n Number of images in '/kaggle/working/ccpd_subset_base/train': 50000\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"rows   = []\n\nfor fname in os.listdir(folder_path):\n    if not fname.endswith(\".jpg\"): continue\n\n    parts = fname[:-4].split(\"-\")\n    if len(parts) < 6: continue\n\n    x1,y1,x2,y2 = split_bbox(parts[2])\n    plate = decode_plate(parts[4])\n\n    rows.append({\n        \"image_path\": os.path.join(folder_path, fname),\n        \"x1_bbox\": x1, \"y1_bbox\": y1,\n        \"x2_bbox\": x2, \"y2_bbox\": y2,\n        \"plate_number\": plate\n    })\n\ndf = pd.DataFrame(rows)\nprint(\"Rows number:\", len(df))\nprint(\"Columns numner:\", df.shape[1])\nprint(\"Shape:\", df.shape)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:10:21.775646Z","iopub.execute_input":"2025-07-15T13:10:21.775919Z","iopub.status.idle":"2025-07-15T13:10:22.140050Z","shell.execute_reply.started":"2025-07-15T13:10:21.775901Z","shell.execute_reply":"2025-07-15T13:10:22.139290Z"}},"outputs":[{"name":"stdout","text":"Rows number: 50000\nColumns numner: 6\nShape: (50000, 6)\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                          image_path  x1_bbox  y1_bbox  \\\n0  /kaggle/working/ccpd_subset_base/train/0088362...      274      502   \n1  /kaggle/working/ccpd_subset_base/train/0328771...      347      577   \n2  /kaggle/working/ccpd_subset_base/train/0315086...      169      515   \n3  /kaggle/working/ccpd_subset_base/train/0217432...      277      481   \n4  /kaggle/working/ccpd_subset_base/train/0318546...      249      384   \n\n   x2_bbox  y2_bbox plate_number  \n0      462      563      ÁöñAA9388  \n1      614      711      ÁöñAG1X69  \n2      579      612      ÁöñA08S98  \n3      521      578      ÁöñAX4722  \n4      579      497      ÁöñAA8H80  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>x1_bbox</th>\n      <th>y1_bbox</th>\n      <th>x2_bbox</th>\n      <th>y2_bbox</th>\n      <th>plate_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0088362...</td>\n      <td>274</td>\n      <td>502</td>\n      <td>462</td>\n      <td>563</td>\n      <td>ÁöñAA9388</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0328771...</td>\n      <td>347</td>\n      <td>577</td>\n      <td>614</td>\n      <td>711</td>\n      <td>ÁöñAG1X69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0315086...</td>\n      <td>169</td>\n      <td>515</td>\n      <td>579</td>\n      <td>612</td>\n      <td>ÁöñA08S98</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0217432...</td>\n      <td>277</td>\n      <td>481</td>\n      <td>521</td>\n      <td>578</td>\n      <td>ÁöñAX4722</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0318546...</td>\n      <td>249</td>\n      <td>384</td>\n      <td>579</td>\n      <td>497</td>\n      <td>ÁöñAA8H80</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"## DataLoader \n","metadata":{}},{"cell_type":"code","source":"class CCPDPlatesDataset(Dataset):\n    \"\"\"\n    Returns: image tensor, bbox tensor (x1,y1,x2,y2) normalized to [0,1]\n    \"\"\"\n    def __init__(self, dataframe, transforms=None):\n        self.df = dataframe.reset_index(drop=True)\n        self.transforms = transforms or T.Compose([\n            T.Resize(IMG_TARGET_SIZE, interpolation=T.InterpolationMode.BILINEAR),\n            T.ToTensor(), T.Normalize(MEAN, STD)\n        ])\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row.image_path).convert('RGB')\n        w0, h0 = img.size\n\n        # (x1,y1,x2,y2) in original resolution\n        x1,y1,x2,y2 = map(float, (row.x1_bbox, row.y1_bbox, row.x2_bbox, row.y2_bbox))\n\n        # resize image -------------------------------------------------\n        img = self.transforms(img)       # (3, H', W')\n        _, H_r, W_r = img.shape\n\n        # scale bbox to resized img\n        sx, sy = W_r / w0, H_r / h0\n        x1, x2 = x1 * sx, x2 * sx\n        y1, y2 = y1 * sy, y2 * sy\n\n        # normalize to [0,1]\n        x1, x2 = x1 / W_r, x2 / W_r\n        y1, y2 = y1 / H_r, y2 / H_r\n\n        target = torch.tensor([x1, y1, x2, y2], dtype=torch.float32)\n        return img, target\n\n\ntrain_df, val_df = train_test_split(df, test_size=0.20, random_state=SEED)\ntrain_ds = CCPDPlatesDataset(train_df);  val_ds = CCPDPlatesDataset(val_df, transforms=train_ds.transforms)\ntrain_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\nval_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\nprint(f\"Train set: {len(train_df)} img\")\nprint(f\"Val set:   {len(val_df)} img\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:10:25.110225Z","iopub.execute_input":"2025-07-15T13:10:25.110539Z","iopub.status.idle":"2025-07-15T13:10:25.136306Z","shell.execute_reply.started":"2025-07-15T13:10:25.110517Z","shell.execute_reply":"2025-07-15T13:10:25.135740Z"}},"outputs":[{"name":"stdout","text":"Train set: 40000 img\nVal set:   10000 img\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef build_model(n_outputs=4):\n    m = mobilenet_v3_small(weights=None)\n    in_features = m.classifier[-1].in_features\n    m.classifier[-1] = nn.Linear(in_features, n_outputs)\n    return m\n\nmodel = build_model().to(device)\n\nprint(\"Start training...\")\n\n# ---------------------------------------------------------------------\n#  Loss / optim / scheduler\n# ---------------------------------------------------------------------\ncriterion  = nn.SmoothL1Loss()\noptimizer  = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\n# ---------------------------------------------------------------------\n#  Training loop \n# ---------------------------------------------------------------------\n\nbest_val  = float('inf')\n\ndef run_epoch(dl, train=True):\n    model.train() if train else model.eval()\n    loss_sum = 0.0\n    with torch.set_grad_enabled(train):\n        for xb, yb in tqdm(dl, leave=False):\n            xb, yb = xb.to(device), yb.to(device)\n            preds  = model(xb)\n            loss   = criterion(preds, yb)\n            if train:\n                optimizer.zero_grad(set_to_none=True); loss.backward(); optimizer.step()\n            loss_sum += loss.item() * xb.size(0)\n    return loss_sum / len(dl.dataset)\n\nfor epoch in range(1, EPOCHS+1):\n    tl, vl = run_epoch(train_dl, True), run_epoch(val_dl, False)\n    scheduler.step()\n    print(f\"[{epoch:02d}/{EPOCHS}] train {tl:.4f} | val {vl:.4f}\")\n    if vl < best_val:\n        best_val = vl; torch.save(model.state_dict(), \"best_bbox_mobilenet.pth\")\n        print(\"  üî• saved new best\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test set","metadata":{}},{"cell_type":"code","source":"class CCPDTestDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df.reset_index(drop=True)\n        self.transforms = transforms or T.Compose([\n            T.Resize((224, 224)),\n            T.ToTensor(),\n            T.Normalize((0.485, 0.456, 0.406),\n                        (0.229, 0.224, 0.225))\n        ])\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row.image_path).convert('RGB')\n        x1, y1, x2, y2 = row.x1_bbox, row.y1_bbox, row.x2_bbox, row.y2_bbox\n        gt_bbox = np.array([x1, y1, x2, y2], dtype=np.float32)\n        img_t = self.transforms(img)\n        return {\n            \"image_tensor\": img_t,\n            \"gt_bbox\": gt_bbox,\n            \"pil_image\": img,\n            \"image_path\": row.image_path\n        }\n\ndef custom_collate(batch):\n    image_tensors = torch.stack([item[\"image_tensor\"] for item in batch])\n    gt_bboxes = torch.stack([torch.tensor(item[\"gt_bbox\"]) for item in batch])\n    pil_images = [item[\"pil_image\"] for item in batch]\n    image_paths = [item[\"image_path\"] for item in batch]\n    return {\n        \"image_tensor\": image_tensors,\n        \"gt_bbox\": gt_bboxes,\n        \"pil_image\": pil_images,\n        \"image_path\": image_paths\n    }\n\ndef compute_iou(boxA, boxB):\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n    interArea = max(0, xB - xA) * max(0, yB - yA)\n    boxAArea = max(0, boxA[2] - boxA[0]) * max(0, boxA[3] - boxA[1])\n    boxBArea = max(0, boxB[2] - boxB[0]) * max(0, boxB[3] - boxB[1])\n    unionArea = boxAArea + boxBArea - interArea\n    return 0.0 if unionArea == 0 else interArea / unionArea\n\ndef load_model(path='best_bbox_mobilenet.pth'):\n    model = mobilenet_v3_small(weights=None)\n    model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, 4)\n    model.load_state_dict(torch.load(path, map_location='cpu'))\n    model.eval()\n    return model\n\n# ------------------------------------------------\n# Prepara dataframe da una cartella\n# ------------------------------------------------\ndef prepare_dataframe(folder):\n    rows = []\n    for root, _, files in os.walk(folder):\n        for fname in files:\n            if not fname.endswith(\".jpg\"):\n                continue\n            parts = fname[:-4].split(\"-\")\n            if len(parts) < 6:\n                continue\n            x1, y1, x2, y2 = split_bbox(parts[2])\n            plate = decode_plate(parts[4])\n            full_path = os.path.join(root, fname)\n            rows.append({\n                \"image_path\": full_path,\n                \"x1_bbox\": x1,\n                \"y1_bbox\": y1,\n                \"x2_bbox\": x2,\n                \"y2_bbox\": y2,\n                \"plate_number\": plate\n            })\n    return pd.DataFrame(rows)\n\ndef run_test_on_folder(model, folder, device):\n    test_df = prepare_dataframe(folder)\n    ds = CCPDTestDataset(test_df)\n    dl = DataLoader(ds, batch_size=1, shuffle=False, collate_fn=custom_collate)\n\n    ious = []\n    above_thresh = 0\n    total = 0\n    with torch.inference_mode():\n        for batch in dl:\n            xb = batch[\"image_tensor\"].to(device)\n            yb_px = batch[\"gt_bbox\"].numpy()[0]\n            orig_img = batch[\"pil_image\"][0]\n\n            pred_norm = model(xb).squeeze().cpu().numpy()\n            w, h = orig_img.size\n            pred_px = np.array([\n                pred_norm[0] * w,\n                pred_norm[1] * h,\n                pred_norm[2] * w,\n                pred_norm[3] * h\n            ], dtype=np.float32)\n\n            iou = compute_iou(pred_px, yb_px)\n            ious.append(iou)\n\n            if iou > 0.6:\n                above_thresh += 1\n            total += 1\n\n    mean_iou = np.mean(ious) if ious else 0.0\n    perc_above_06 = (above_thresh / total) * 100 if total else 0.0\n    return mean_iou, perc_above_06\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = load_model().to(device)\n\nsubfolders = [\"base\", \"blur\", \"challenge\", \"db\", \"fn\", \"rotate\", \"tilt\", \"weather\"]\n\nroot_dir = \"/kaggle/working/ccpd_test\"\nresults = {}\n\nprint(\"üìä Calcolo IoU medio per ciascuna sottocartella...\\n\")\n\nfor sub in subfolders:\n    folder_path = os.path.join(root_dir, sub)\n    avg_iou, pct_above_06 = run_test_on_folder(model, folder_path, device)\n    results[sub] = (avg_iou, pct_above_06)\n    print(f\"{sub:<10} --> IoU medio: {avg_iou:.4f}, % IoU > 0.6: {pct_above_06:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:27:03.499791Z","iopub.execute_input":"2025-07-15T13:27:03.500372Z","iopub.status.idle":"2025-07-15T13:29:00.249013Z","shell.execute_reply.started":"2025-07-15T13:27:03.500347Z","shell.execute_reply":"2025-07-15T13:29:00.248184Z"}},"outputs":[{"name":"stdout","text":"üìä Calcolo IoU medio per ciascuna sottocartella...\n\nbase       --> IoU medio: 0.8368, % IoU > 0.6: 99.10%\nblur       --> IoU medio: 0.6863, % IoU > 0.6: 74.90%\nchallenge  --> IoU medio: 0.7003, % IoU > 0.6: 80.10%\ndb         --> IoU medio: 0.6112, % IoU > 0.6: 58.60%\nfn         --> IoU medio: 0.6395, % IoU > 0.6: 65.00%\nrotate     --> IoU medio: 0.7431, % IoU > 0.6: 88.90%\ntilt       --> IoU medio: 0.7181, % IoU > 0.6: 81.50%\nweather    --> IoU medio: 0.8310, % IoU > 0.6: 98.80%\n","output_type":"stream"}],"execution_count":34}]}