{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:37:52.824748Z",
     "iopub.status.busy": "2025-07-11T11:37:52.824021Z",
     "iopub.status.idle": "2025-07-11T11:37:52.831221Z",
     "shell.execute_reply": "2025-07-11T11:37:52.830527Z",
     "shell.execute_reply.started": "2025-07-11T11:37:52.824720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "working_on_kaggle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:37:52.840083Z",
     "iopub.status.busy": "2025-07-11T11:37:52.839511Z",
     "iopub.status.idle": "2025-07-11T11:40:01.031930Z",
     "shell.execute_reply": "2025-07-11T11:40:01.031041Z",
     "shell.execute_reply.started": "2025-07-11T11:37:52.840059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if working_on_kaggle:\n",
    "    !pip install --quiet gdown\n",
    "    !apt-get install -y fonts-noto-cjk > /dev/null\n",
    "\n",
    "    import os\n",
    "    \n",
    "    from getpass import getpass\n",
    "    \n",
    "    token = getpass('Your GitHub token: ')\n",
    "    username = \"iamlucaconti\"\n",
    "    repo_name = \"PDDLR-algorithm\"\n",
    "    git_url = f\"https://{username}:{token}@github.com/giankev/{repo_name}.git\"\n",
    "    os.system(f\"git clone {git_url} /kaggle/working/{repo_name}\")\n",
    "    %cd PDDLR-algorithm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:40:01.033685Z",
     "iopub.status.busy": "2025-07-11T11:40:01.033429Z",
     "iopub.status.idle": "2025-07-11T11:40:09.923226Z",
     "shell.execute_reply": "2025-07-11T11:40:09.922584Z",
     "shell.execute_reply.started": "2025-07-11T11:40:01.033662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from tqdm import tqdm\n",
    "import gdown\n",
    "import tarfile\n",
    "from PIL import Image\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset \n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('./scr/')\n",
    "from pdlpr import PDLPR \n",
    "from trainer import train, set_seed, evaluate_model\n",
    "from augmentation import RandomMotionBlur, RandomGaussianBlur, AddNoise, SimulateDistance, AddFog, MatrixEffect, RandomLightBeam, RandomColorPad, BluePlateHighlight\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractor import IGFE\n",
    "igfe = IGFE()\n",
    "igfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:40:09.924388Z",
     "iopub.status.busy": "2025-07-11T11:40:09.924026Z",
     "iopub.status.idle": "2025-07-11T11:40:09.942501Z",
     "shell.execute_reply": "2025-07-11T11:40:09.941895Z",
     "shell.execute_reply.started": "2025-07-11T11:40:09.924370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 5\n",
    "VAL_SPLIT_SIZE = 0.2\n",
    "NUM_SAMPLES = 500\n",
    "num_epochs = 5\n",
    "lr = 1e-4  # da 1 a 20 1e-4, da 21 a 40 0.8*1e-4, da 41 a 60 (0.8)^2*1e^-4\n",
    "lr_decay_factor = 0.8\n",
    "lr_decay_epochs = 20\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "save_checkpoint_path = \"pdlpr_checkpoints/\" # or None\n",
    "name_checkpoint = None # or None\n",
    "\n",
    "if name_checkpoint is not None:\n",
    "    load_checkpoint_path =  os.path.join(save_checkpoint_path, name_checkpoint) \n",
    "else:\n",
    "    load_checkpoint_path = None\n",
    "    \n",
    "extract_path = 'dataset'\n",
    "output_path = 'dataset/ccpd_subset_base.tar'\n",
    "folder_path = os.path.join(extract_path, 'ccpd_subset_base', 'train')\n",
    "cropped_folder = \"dataset/ccpd_cropped\"\n",
    "font_path =  \"C:/Windows/Fonts/msyh.ttc\"\n",
    "\n",
    "\n",
    "kaggle_working_folder = '/kaggle/working/PDDLR-algorithm/'\n",
    "if working_on_kaggle:\n",
    "    NUM_WORKERS = 2\n",
    "    print(\"Creating \", save_checkpoint_path)\n",
    "    save_checkpoint_path = os.path.join(kaggle_working_folder, save_checkpoint_path)\n",
    "    os.makedirs(save_checkpoint_path, exist_ok=True)\n",
    "    \n",
    "    if load_checkpoint_path is not None:\n",
    "        load_checkpoint_path = os.path.join(save_checkpoint_path, name_checkpoint)\n",
    "        # TODO: togliere la riga seguente in futuro\n",
    "        load_checkpoint_path = '/kaggle/input/pdlpr-checkpoint/checkpoint_epoch60.pt'\n",
    "\n",
    "    \n",
    "    output_path = os.path.join(kaggle_working_folder, output_path)\n",
    "    extract_path = os.path.join(kaggle_working_folder, extract_path)\n",
    "    folder_path = os.path.join(extract_path, 'ccpd_subset_base', 'train')\n",
    "    cropped_folder = os.path.join(kaggle_working_folder, cropped_folder)\n",
    "    font_path = \"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\"\n",
    "    \n",
    "prop = fm.FontProperties(fname=font_path)\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "os.makedirs(cropped_folder, exist_ok=True)\n",
    "\n",
    "if load_checkpoint_path is not None and not os.path.isfile(load_checkpoint_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint file not found: {load_checkpoint_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:40:09.944577Z",
     "iopub.status.busy": "2025-07-11T11:40:09.944341Z",
     "iopub.status.idle": "2025-07-11T11:40:09.966446Z",
     "shell.execute_reply": "2025-07-11T11:40:09.965869Z",
     "shell.execute_reply.started": "2025-07-11T11:40:09.944560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\",\n",
    "             \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N',\n",
    "             'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'O']\n",
    "\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R',\n",
    "       'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "unique_chars = set(provinces[:-1] + alphabets[:-1] + ads[:-1])  # escludi 'O'\n",
    "char_list = sorted(list(unique_chars))  # ordinamento per coerenza\n",
    "char_list = [\"-\"] + char_list\n",
    "char2idx = {char: i for i, char in enumerate(char_list)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "num_classes = len(char_list)\n",
    "print(\"Num classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:40:09.967467Z",
     "iopub.status.busy": "2025-07-11T11:40:09.967228Z",
     "iopub.status.idle": "2025-07-11T11:40:09.993735Z",
     "shell.execute_reply": "2025-07-11T11:40:09.993021Z",
     "shell.execute_reply.started": "2025-07-11T11:40:09.967445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def decode_plate(s):\n",
    "    idx   = list(map(int, s.split(\"_\")))\n",
    "    try:\n",
    "        return provinces[idx[0]] + alphabets[idx[1]] + \"\".join(ads[i] for i in idx[2:])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def split_bbox(bbox_str):\n",
    "    # Split on one or more underscores\n",
    "    tokens = re.split(r'_+', bbox_str)\n",
    "    if len(tokens) == 4 and all(t.isdigit() for t in tokens):\n",
    "        return tuple(map(int, tokens))\n",
    "    return (None,) * 4\n",
    "\n",
    "def crop_and_resize(img, x1, y1, x2, y2):\n",
    "    # Controlla che il bounding box sia valido\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    \n",
    "    # Ritaglia\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Controlla che l'immagine ritagliata non sia vuota\n",
    "    if cropped_img.size == 0:\n",
    "        return None\n",
    "\n",
    "    # Resize a 48x144\n",
    "    try:\n",
    "        return cv2.resize(cropped_img, (144, 48))\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def decode_ccpd_label(label_str, provinces, alphabets, ads):\n",
    "    \"\"\"Decodifica stringa del tipo '0_0_22_27_27_33_16' in targa es. '皖AWWX6G' \"\"\"\n",
    "    indices = list(map(int, label_str.strip().split('_')))\n",
    "    if len(indices) != 7:\n",
    "        raise ValueError(\"Label must contain 7 indices\")\n",
    "\n",
    "    province = provinces[indices[0]]\n",
    "    alphabet = alphabets[indices[1]]\n",
    "    ad_chars = [ads[i] for i in indices[2:]]\n",
    "\n",
    "    return province + alphabet + ''.join(ad_chars)\n",
    "\n",
    "def encode_plate(plate_str, char2idx):\n",
    "    \"\"\"Converte la stringa '皖AWWX6G' in lista di indici [3, 12, 30, 30, ...]\"\"\"\n",
    "    return [char2idx[c] for c in plate_str]\n",
    "\n",
    "def decode_plate_from_list(label_indices, idx2char):\n",
    "    \"\"\"Converte una lista di indici [3, 12, 30, ...] nella stringa '皖AWWX6G'\"\"\"\n",
    "    return ''.join([idx2char[i] for i in label_indices])\n",
    "\n",
    "def greedy_decode(logits, blank_index, idx2char):\n",
    "    preds = logits.argmax(dim=2)  # (B, T)\n",
    "    decoded_batch = []\n",
    "    for pred in preds:\n",
    "        chars = []\n",
    "        prev = None\n",
    "        for p in pred:\n",
    "            p = p.item()\n",
    "            if p != blank_index and p != prev:\n",
    "                chars.append(idx2char[p])\n",
    "            prev = p\n",
    "        decoded_batch.append(''.join(chars))\n",
    "    return decoded_batch\n",
    "\n",
    "\n",
    "def download_and_extract_dataset(url, output_path, extract_path, extracted_folder_path):\n",
    "    \"\"\"\n",
    "    Downloads and extracts a dataset if not already present.\n",
    "\n",
    "    Args:\n",
    "        url (str): Google Drive URL of the dataset.\n",
    "        output_path (str): Path where the .tar file will be saved.\n",
    "        extract_path (str): Directory where the archive will be extracted.\n",
    "        extracted_folder_path (str): Expected folder resulting from extraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download the dataset if it doesn't already exist\n",
    "    if not os.path.exists(output_path):\n",
    "        print(\"Downloading the dataset...\")\n",
    "        gdown.download(url, output_path, fuzzy=True, quiet=False)\n",
    "    else:\n",
    "        print(\"Dataset already exists, download skipped.\")\n",
    "\n",
    "    # Extract the dataset if the folder doesn't already exist\n",
    "    if not os.path.exists(extracted_folder_path):\n",
    "        print(\"Extracting the dataset...\")\n",
    "        os.makedirs(extract_path, exist_ok=True)\n",
    "        with tarfile.open(output_path) as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "        print(\"Extraction completed.\")\n",
    "    else:\n",
    "        print(\"Dataset folder already exists, extraction skipped.\")\n",
    "\n",
    "\n",
    "def create_dataframe(folder_path, char2idx):\n",
    "    all_files = sorted(os.listdir(folder_path))\n",
    "    jpg_files = [f for f in all_files if f.endswith('.jpg')]\n",
    "\n",
    "    rows = []\n",
    "    for fname in jpg_files:\n",
    "        parts = fname[:-4].split(\"-\")\n",
    "        if len(parts) < 6:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            x1, y1, x2, y2 = split_bbox(parts[2])\n",
    "            plate = decode_plate(parts[4])\n",
    "            label = encode_plate(plate, char2idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Errore con file {fname}: {e}\")\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"image_path\": os.path.join(folder_path, fname),\n",
    "            \"x1_bbox\": x1, \"y1_bbox\": y1,\n",
    "            \"x2_bbox\": x2, \"y2_bbox\": y2,\n",
    "            \"plate_number\": plate,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def create_cropped_dataframe(df, cropped_folder):\n",
    "    \"\"\"\n",
    "    Crea un nuovo DataFrame con le immagini ritagliate e ridimensionate.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame originale con bounding box e info.\n",
    "        cropped_folder (str): Cartella dove salvare le immagini ritagliate.\n",
    "        crop_and_resize_fn (function): Funzione che riceve (img, x1, y1, x2, y2) e restituisce l'immagine ritagliata e ridimensionata.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Nuovo DataFrame con path immagini ritagliate, plate_number e label.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(cropped_folder, exist_ok=True)\n",
    "    cropped_rows = []\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        image_path = row[\"image_path\"]\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Immagine non trovata o corrotta: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            x1 = int(float(row[\"x1_bbox\"]))\n",
    "            y1 = int(float(row[\"y1_bbox\"]))\n",
    "            x2 = int(float(row[\"x2_bbox\"]))\n",
    "            y2 = int(float(row[\"y2_bbox\"]))\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nei bounding box per {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        resized_img = crop_and_resize(img, x1, y1, x2, y2)\n",
    "        if resized_img is None:\n",
    "            print(f\"Errore nel crop/resize dell'immagine: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        cropped_path = os.path.join(cropped_folder, f\"cropped_{i}.jpg\")\n",
    "        cv2.imwrite(cropped_path, resized_img)\n",
    "\n",
    "        cropped_rows.append({\n",
    "            \"image_path\": cropped_path,\n",
    "            \"plate_number\": row[\"plate_number\"],\n",
    "            \"label\": row[\"label\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(cropped_rows)\n",
    "\n",
    "def plot_batch_images(train_loader, idx2char, font=prop):\n",
    "    images, labels = next(iter(train_loader))\n",
    "    \n",
    "    # Seleziona 20 indici casuali dal batch\n",
    "    indices = np.random.choice(len(images), size=25, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(20, 10))  \n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, idx in zip(axes, indices):\n",
    "        image = images[idx]\n",
    "        label = labels[idx]\n",
    "\n",
    "        decoded_plate = decode_plate_from_list([int(i) for i in label], idx2char)\n",
    "        img_np = to_pil_image(image)\n",
    "\n",
    "        ax.imshow(img_np)\n",
    "        ax.set_title(f\"Plate: {decoded_plate}\", fontproperties=font, fontsize=18)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:40:09.994613Z",
     "iopub.status.busy": "2025-07-11T11:40:09.994451Z",
     "iopub.status.idle": "2025-07-11T11:41:08.062007Z",
     "shell.execute_reply": "2025-07-11T11:41:08.060931Z",
     "shell.execute_reply.started": "2025-07-11T11:40:09.994600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_id = '1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "download_and_extract_dataset(url, output_path, extract_path, folder_path)\n",
    "\n",
    "if working_on_kaggle:\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:41:08.063195Z",
     "iopub.status.busy": "2025-07-11T11:41:08.062914Z",
     "iopub.status.idle": "2025-07-11T11:41:08.821594Z",
     "shell.execute_reply": "2025-07-11T11:41:08.820824Z",
     "shell.execute_reply.started": "2025-07-11T11:41:08.063167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = create_dataframe(folder_path, char2idx)\n",
    "\n",
    "df = df[:NUM_SAMPLES] #TODO: ricordiamo di togliere questo\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop and resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:30:50.161817Z",
     "iopub.status.busy": "2025-07-11T13:30:50.161267Z",
     "iopub.status.idle": "2025-07-11T13:30:50.446972Z",
     "shell.execute_reply": "2025-07-11T13:30:50.446344Z",
     "shell.execute_reply.started": "2025-07-11T13:30:50.161793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame with the cropped images\n",
    "if os.path.isdir(cropped_folder):\n",
    "    num_files = len([f for f in os.listdir(cropped_folder) if os.path.isfile(os.path.join(cropped_folder, f))])\n",
    "    print(f\"Found {num_files} files in '{cropped_folder}' (expected: {NUM_SAMPLES})\")\n",
    "\n",
    "    if num_files == NUM_SAMPLES:\n",
    "        print(\"Cropped folder already processed. Skipping cropping step.\")\n",
    "    else:\n",
    "        print(\"Cropped folder incomplete. Reprocessing...\")\n",
    "        cropped_df = create_cropped_dataframe(df, cropped_folder)\n",
    "else:\n",
    "    print(f\"The folder '{cropped_folder}' doesn't exist. Creating and processing...\")\n",
    "    os.makedirs(cropped_folder, exist_ok=True)\n",
    "    cropped_df = create_cropped_dataframe(df, cropped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:44:02.095355Z",
     "iopub.status.busy": "2025-07-11T11:44:02.095111Z",
     "iopub.status.idle": "2025-07-11T11:44:02.541258Z",
     "shell.execute_reply": "2025-07-11T11:44:02.540253Z",
     "shell.execute_reply.started": "2025-07-11T11:44:02.095326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Choose a sample in the dataset\n",
    "i = np.random.randint(0, len(df))\n",
    "img = cv2.imread(df.iloc[i][\"image_path\"])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converti in RGB per matplotlib\n",
    "\n",
    "# Draw the bounding box\n",
    "x1, y1 = int(df.iloc[i][\"x1_bbox\"]), int(df.iloc[i][\"y1_bbox\"])\n",
    "x2, y2 = int(df.iloc[i][\"x2_bbox\"]), int(df.iloc[i][\"y2_bbox\"])\n",
    "cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "\n",
    "# Aggiungi la targa decodificata sull’immagine (con OpenCV)\n",
    "plate_text = df.iloc[i]['plate_number']\n",
    "\n",
    "# Mostra l'immagine con titolo che usa il font CJK di matplotlib\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Plate: {plate_text}\", fontproperties=prop)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "img = cv2.imread(cropped_df.iloc[i][\"image_path\"])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Plate: {plate_text}\", fontproperties=prop)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset personalizzato\n",
    "class PlateDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = row[\"label\"]  # list\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:44:02.544320Z",
     "iopub.status.busy": "2025-07-11T11:44:02.544076Z",
     "iopub.status.idle": "2025-07-11T11:44:02.564869Z",
     "shell.execute_reply": "2025-07-11T11:44:02.564102Z",
     "shell.execute_reply.started": "2025-07-11T11:44:02.544301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To handle with CCPD-DB: Illuminations on the LP area are dark, uneven or extremely bright.\n",
    "# Simulate night\n",
    "transform_night = transforms.Compose([\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.1, 0.3), angle_range=(-20, 20), beam_width_range=(10, 60), beam_type = \"black\")],\n",
    "                            p=0.6),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.1, 0.3), angle_range=(-20, 20), beam_width_range=(10, 60), beam_type = \"black\")],\n",
    "                            p=0.6),\n",
    "\n",
    "    AddNoise(noise_level=(0.005, 0.05), p=0.6),\n",
    "    RandomGaussianBlur(radius=(0.1, 1), p=0.7),\n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.7),\n",
    "\n",
    "    BluePlateHighlight(intensity_range=(1, 1.6), p=0.75),\n",
    "    MatrixEffect(intensity=(0.7, 0.9), p=0.85),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(  \n",
    "            brightness=(0.4, 0.7),     \n",
    "            contrast=(1, 2.5),       \n",
    "            )], p=0.60),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(       \n",
    "            saturation=(0.5, 1),     \n",
    "            )], p=0.60),\n",
    "   \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   \n",
    "            brightness=(0.4, 0.7),     \n",
    "            contrast=(1, 2),       \n",
    "            )], p=0.60),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(     \n",
    "            # contrast=(1, 2),       \n",
    "            saturation=(0.4, 1),     \n",
    "            )], p=0.60),\n",
    "\n",
    "    SimulateDistance(scale_range=(0.5, 0.7), p=0.95),             \n",
    "    # transforms.RandomPerspective(distortion_scale=0.30, p=0.20),\n",
    "    \n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# Simulate brightness\n",
    "transform_day = transforms.Compose([\n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.30),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   # For \"db\" and \"challenge\" datasets\n",
    "            brightness=(1.2, 2),     \n",
    "            contrast=(1, 1.5),       \n",
    "            saturation=(0.6, 1.4),     \n",
    "            hue=(-0.05, 0.05)),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    AddNoise(noise_level=(0.001, 0.01), p=0.2),\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.5, 0.9), angle_range=(-20, 20), beam_width_range=(20, 80), beam_type = \"white\")],\n",
    "                            p=0.4),\n",
    "    AddFog(fog_factor=(0.2, 0.7), p=0.2),\n",
    "    transforms.RandomPerspective(distortion_scale=0.30, p=0.20),\n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# To handle CPD-FN: The distance from the LP to the shooting location is relatively far or near.\n",
    "transform_fn = transforms.Compose([\n",
    "    # Trasformazione 5\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.4), angle_range=(-20, 20), beam_width_range=(10, 40), beam_type = \"black\")],\n",
    "                            p=0.4),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.4), angle_range=(-20, 20), beam_width_range=(10, 40), beam_type = \"white\")],\n",
    "                            p=0.4),\n",
    "    AddNoise(noise_level=(0.005, 0.1), p=0.6),\n",
    "    RandomMotionBlur(kernel_size=(7, 9), p=0.6),\n",
    "    RandomGaussianBlur(radius=(0.5, 2), p=0.6),                       \n",
    "    SimulateDistance(scale_range=(0.25, 0.45), p=0.95),\n",
    "    SimulateDistance(scale_range=(0.6, 0.8), p=0.2),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   # For \"db\" and \"challenge\" datasets\n",
    "             brightness=(0.6, 1.0),     \n",
    "            contrast=(0.8, 1.2),       \n",
    "            saturation=(0.4, .8),     \n",
    "            hue=(-0.05, 0.05)),\n",
    "    ], p=0.8),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.20),\n",
    "    \n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# To handle with CCPD-Blur: Blurry largely due to hand jitter while taking pictures.\n",
    "transform_blur = transforms.Compose([\n",
    "    RandomMotionBlur(kernel_size=(9, 12), p=0.90),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   # For \"db\" and \"challenge\" datasets\n",
    "            brightness=(0.6, 1.4),     \n",
    "            contrast=(0.6, 1.4),       \n",
    "            saturation=(0.6, 1.4),     \n",
    "            hue=(-0.05, 0.05)),\n",
    "    ], p=0.8),\n",
    "\n",
    "    SimulateDistance(scale_range=(0.1, 0.4), p=0.30),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.40),\n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# CCPD-Rotate Great horizontal tilt degree (20◦ - 50◦) and the vertical tilt degree varies from -10◦ to 10◦.\n",
    "# transform_rot_1 = transforms.Compose([\n",
    "#     RandomColorPad(pad=(10, 20, 10, 20)),\n",
    "    \n",
    "#     transforms.RandomApply([\n",
    "#         transforms.ColorJitter(\n",
    "#             brightness=(0.6, 1.4),     \n",
    "#             contrast=(0.6, 1.4),       \n",
    "#             saturation=(0.6, 1.4),     \n",
    "#             hue=(-0.08, 0.08)),\n",
    "#     ], p=0.90),\n",
    "    \n",
    "    \n",
    "#     transforms.RandomApply([\n",
    "#         transforms.RandomAffine(\n",
    "#             scale=(0.7, 0.9),\n",
    "#             degrees=(-20, -15),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "#             # translate=(0.10, 0.10),\n",
    "#             shear=(-10, 10, -10, 10),                \n",
    "#             fill=0\n",
    "#         )\n",
    "#     ], p=0.95),\n",
    "\n",
    "#     AddNoise(noise_level=(0.005, 0.1), p=0.4),\n",
    "#     RandomGaussianBlur(radius=(0.1, 0.5), p=0.4),    \n",
    "#     RandomMotionBlur(kernel_size=(5, 7), p=0.4),\n",
    "#     SimulateDistance(scale_range=(0.6, 0.9), p=0.30),\n",
    "#     # transforms.RandomPerspective(distortion_scale=0.4, p=0.30),\n",
    "#     transforms.CenterCrop((60, 180)),\n",
    "#     transforms.Resize((48, 144)),\n",
    "#     transforms.CenterCrop((48, 90)),\n",
    "#     transforms.Resize((48, 144)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# transform_rot_2 = transforms.Compose([\n",
    "#     RandomColorPad(pad=(10, 20, 10, 20)),\n",
    "    \n",
    "#     transforms.RandomApply([\n",
    "#         transforms.ColorJitter(\n",
    "#             brightness=(0.6, 1.4),     \n",
    "#             contrast=(0.6, 1.4),       \n",
    "#             saturation=(0.6, 1.4),     \n",
    "#             hue=(-0.08, 0.08)),\n",
    "#     ], p=0.90),\n",
    "    \n",
    "    \n",
    "#     transforms.RandomApply([\n",
    "#         transforms.RandomAffine(\n",
    "#             scale=(0.7, 0.9),\n",
    "#             degrees=(15, 20),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "#             # translate=(0.10, 0.10),\n",
    "#             shear=(-10, 10, -10, 10),                \n",
    "#             fill=0\n",
    "#         )\n",
    "#     ], p=0.95),\n",
    "\n",
    "#     AddNoise(noise_level=(0.005, 0.1), p=0.4),\n",
    "#     RandomGaussianBlur(radius=(0.1, 0.5), p=0.4),    \n",
    "#     RandomMotionBlur(kernel_size=(5, 7), p=0.4),\n",
    "#     SimulateDistance(scale_range=(0.6, 0.9), p=0.30),\n",
    "#     # transforms.RandomPerspective(distortion_scale=0.4, p=0.30),\n",
    "#     transforms.CenterCrop((60, 180)),\n",
    "#     transforms.Resize((48, 144)),\n",
    "#     transforms.CenterCrop((48, 90)),\n",
    "#     transforms.Resize((48, 144)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# To handle with CCPD-Tilt Great horizontal tilt degree and vertical tilt degree.\n",
    "transform_tilt_1 = transforms.Compose([\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.7, 1.3),     \n",
    "            contrast=(0.7, 1.3),       \n",
    "            saturation=(0.7, 1.3),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.5),\n",
    "\n",
    "    transforms.RandomApply([RandomColorPad(pad_y_range=(10, 40), pad_x_range=(15, 25), color_pad='random')], p=0.99),\n",
    "    \n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            # scale=(0.9, 1.1),\n",
    "            degrees=(-0, 0),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-25, -10, -18, -5),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.95),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.45, p=0.90),\n",
    "    \n",
    "    RandomGaussianBlur(radius=(0.05, 0.15), p=0.20),\n",
    "    RandomMotionBlur(kernel_size=(2, 4), p=0.2),\n",
    "    SimulateDistance(scale_range=(0.8, 1), p=0.20),\n",
    "    \n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.CenterCrop((40, 110)),\n",
    "    transforms.Resize((48, 144)),\n",
    "\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_tilt_2 = transforms.Compose([\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.7, 1.3),     \n",
    "            contrast=(0.7, 1.3),       \n",
    "            saturation=(0.7, 1.3),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.5),\n",
    "\n",
    "    transforms.RandomApply([RandomColorPad(pad_y_range=(10, 40), pad_x_range=(15, 25), color_pad='random')], p=0.99),\n",
    "    \n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            # scale=(0.9, 1.1),\n",
    "            degrees=(-0, 0),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(10, 25, 5, 18),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.95),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.45, p=0.90),\n",
    "    \n",
    "    RandomGaussianBlur(radius=(0.05, 0.15), p=0.20),\n",
    "    RandomMotionBlur(kernel_size=(2, 4), p=0.2),\n",
    "    SimulateDistance(scale_range=(0.8, 1), p=0.20),\n",
    "    \n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.CenterCrop((40, 110)),\n",
    "    transforms.Resize((48, 144)),\n",
    "\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# To handle with CCPD-Challenge: The most challenging images for LPDR to date.\n",
    "transform_challenge = transforms.Compose([\n",
    "     transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.4), angle_range=(-20, 20), beam_width_range=(20, 50), beam_type = \"black\")],\n",
    "                            p=0.4),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.4), angle_range=(-20, 20), beam_width_range=(20, 50), beam_type = \"white\")],\n",
    "                            p=0.4),\n",
    "\n",
    "    AddNoise(noise_level=(0.005, 0.05), p=0.4),\n",
    "    RandomMotionBlur(kernel_size=(7, 9), p=0.6),\n",
    "    # AddNoise(noise_level=(0.005, 0.05), p=0.4), \n",
    "    RandomGaussianBlur(radius=(0.5, 2), p=0.6),                    \n",
    "    SimulateDistance(scale_range=(0.25, 0.45), p=0.80),\n",
    "    MatrixEffect(intensity=(0.8, 1), p=0.2),\n",
    "    # \n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.5, 1.5),     \n",
    "            contrast=(0.5, 1.5),       \n",
    "            saturation=(0.5, 1.5),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.70),\n",
    "\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.40),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            scale=(0.9, 1),\n",
    "            degrees=(-10, 10),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-5, 5, -5, 5),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.6),\n",
    "    \n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# Solo normalizzazione (niente data augmentation) per validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-10T11:55:45.939510Z",
     "iopub.status.busy": "2025-07-10T11:55:45.938679Z",
     "iopub.status.idle": "2025-07-10T11:55:48.532434Z",
     "shell.execute_reply": "2025-07-10T11:55:48.531538Z",
     "shell.execute_reply.started": "2025-07-10T11:55:45.939481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(cropped_df, test_size=VAL_SPLIT_SIZE, shuffle=True, random_state=SEED)\n",
    "dfs = np.array_split(train_df, 1)\n",
    "\n",
    "# dataset_night = PlateDataset(dfs[0], transform=transform_night)\n",
    "# dataset_day = PlateDataset(dfs[1], transform=transform_day)\n",
    "# dataset_fn = PlateDataset(dfs[2], transform=transform_fn)\n",
    "# dataset_blur = PlateDataset(dfs[3], transform=transform_blur)\n",
    "# idx_tilt = int(0.5 * len(dfs[4]))\n",
    "# dataset_tilt_1 = PlateDataset(dfs[4][:idx_tilt], transform=transform_tilt_1)\n",
    "# dataset_tilt_2 = PlateDataset(dfs[4][idx_tilt:], transform=transform_tilt_2)\n",
    "# idx_rot = int(0.5 * len(dfs[5]))\n",
    "# dataset_rot_1 = PlateDataset(dfs[5][:idx_rot], transform=transform_rot_1)\n",
    "# dataset_rot_2 = PlateDataset(dfs[5][:idx_rot], transform=transform_rot_2)\n",
    "# dataset_challenge = PlateDataset(dfs[6], transform=transform_challenge)\n",
    "\n",
    "idx_tilt = int(0.5 * len(dfs[0]))\n",
    "dataset_tilt_1 = PlateDataset(dfs[0][:idx_tilt], transform=transform_tilt_1)\n",
    "dataset_tilt_2 = PlateDataset(dfs[0][idx_tilt:], transform=transform_tilt_2)\n",
    "\n",
    "augmented_dataset = ConcatDataset([\n",
    "    # dataset_night,\n",
    "    # dataset_day,\n",
    "    # dataset_fn,\n",
    "    # dataset_blur,\n",
    "    dataset_tilt_1,\n",
    "    dataset_tilt_2,\n",
    "    # dataset_rot_1,\n",
    "    # dataset_rot_2,\n",
    "    # dataset_challenge\n",
    " ])\n",
    "\n",
    "val_dataset = PlateDataset(val_df, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(augmented_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "plot_batch_images(train_loader, idx2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T11:44:05.398739Z",
     "iopub.status.busy": "2025-07-11T11:44:05.398540Z",
     "iopub.status.idle": "2025-07-11T13:12:20.372150Z",
     "shell.execute_reply": "2025-07-11T13:12:20.371284Z",
     "shell.execute_reply.started": "2025-07-11T11:44:05.398720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = PDLPR(num_classes=num_classes) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Number of GPU: {torch.cuda.device_count()}\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "print(\"Start training...\")\n",
    "model, train_losses, val_losses = train(train_loader, val_loader, model, char2idx, 'cuda', num_epochs,\n",
    "      lr, load_checkpoint_path, save_checkpoint_path, lr_decay_factor, lr_decay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:12:20.374112Z",
     "iopub.status.busy": "2025-07-11T13:12:20.373623Z",
     "iopub.status.idle": "2025-07-11T13:12:20.563898Z",
     "shell.execute_reply": "2025-07-11T13:12:20.563109Z",
     "shell.execute_reply.started": "2025-07-11T13:12:20.374084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Andamento della Loss durante il Training')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:12:20.564982Z",
     "iopub.status.busy": "2025-07-11T13:12:20.564746Z",
     "iopub.status.idle": "2025-07-11T13:12:20.573352Z",
     "shell.execute_reply": "2025-07-11T13:12:20.572582Z",
     "shell.execute_reply.started": "2025-07-11T13:12:20.564952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def infer_and_evaluate(model, image_tensor, target_indices, char2idx, idx2char, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Assumiamo batch_size = 1\n",
    "    images = image_tensor.unsqueeze(0).to(device)       # (1, C, H, W)\n",
    "    targets = [target_indices.to(device)]               # list of tensors\n",
    "    target_lengths = torch.tensor([len(t) for t in targets], dtype=torch.long, device=device)\n",
    "    targets_concat = torch.cat(targets)                 # flatten targets\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(images)                              # (1, T, C)\n",
    "\n",
    "    # Decoding (greedy)\n",
    "    blank_idx = char2idx['-']\n",
    "    decoded = greedy_decode(logits, blank_idx, idx2char)\n",
    "\n",
    "    # Prepare input for CTC loss\n",
    "    log_probs = F.log_softmax(logits, dim=2).permute(1, 0, 2)  # (T, N, C)\n",
    "    input_lengths = torch.full(size=(1,), fill_value=log_probs.size(0), dtype=torch.long).to(device)\n",
    "\n",
    "    # CTC Loss\n",
    "    ctc_loss_fn = nn.CTCLoss(blank=blank_idx, zero_infinity=True)\n",
    "    loss = ctc_loss_fn(log_probs, targets_concat, input_lengths, target_lengths)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Predetta: {decoded[0]}\")\n",
    "    print(f\"Target:   {decode_plate_from_list(target_indices.tolist(), idx2char)}\")\n",
    "    print(f\"CTC Loss: {loss.item():.4f}\")\n",
    "    print(f\"Len pred: {len(decoded[0])}, Len true: {target_lengths.item()}\")\n",
    "\n",
    "    return decoded[0], loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:12:20.574306Z",
     "iopub.status.busy": "2025-07-11T13:12:20.574063Z",
     "iopub.status.idle": "2025-07-11T13:12:20.899440Z",
     "shell.execute_reply": "2025-07-11T13:12:20.898652Z",
     "shell.execute_reply.started": "2025-07-11T13:12:20.574276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(val_loader))\n",
    "i = np.random.randint(0, len(images))\n",
    "print(i)\n",
    "\n",
    "# First image and label\n",
    "first_image = images[i]\n",
    "first_label = labels[i]\n",
    "\n",
    "\n",
    "decoded_str, loss_value = infer_and_evaluate(model, first_image, first_label, char2idx, idx2char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:12:20.901229Z",
     "iopub.status.busy": "2025-07-11T13:12:20.900911Z",
     "iopub.status.idle": "2025-07-11T13:13:24.097808Z",
     "shell.execute_reply": "2025-07-11T13:13:24.096729Z",
     "shell.execute_reply.started": "2025-07-11T13:12:20.901180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_output_path = 'dataset/ccpd_test.tar'\n",
    "test_extract_path = 'dataset'\n",
    "test_folder_path = os.path.join(test_extract_path, 'ccpd_test')  # cartella che sarà estratta\n",
    "test_cropped_folder = 'dataset/ccpd_test_cropped'\n",
    "\n",
    "# Adatta i percorsi se stai lavorando su Kaggle\n",
    "if working_on_kaggle:\n",
    "    test_output_path = '/kaggle/working/ccpd_test.tar'\n",
    "    test_extract_path = '/kaggle/working/dataset'\n",
    "    test_folder_path = os.path.join(test_extract_path, 'ccpd_test')\n",
    "    test_cropped_folder = '/kaggle/working/ccpd_test_cropped'\n",
    "\n",
    "# Crea cartelle se non esistono\n",
    "os.makedirs(os.path.dirname(test_output_path), exist_ok=True)\n",
    "os.makedirs(test_cropped_folder, exist_ok=True)\n",
    "\n",
    "# URL_TEST di download\n",
    "file_id_test = '1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X'\n",
    "url_test = f'https://drive.google.com/uc?id={file_id_test}'\n",
    "\n",
    "download_and_extract_dataset(url_test, test_output_path, test_extract_path, test_folder_path)\n",
    "\n",
    "if os.path.exists(test_folder_path):\n",
    "    subfolders = [name for name in os.listdir(test_folder_path)\n",
    "                  if os.path.isdir(os.path.join(test_folder_path, name))]\n",
    "    subfolders = sorted(subfolders)\n",
    "    print(f\"Subfolders in '{test_folder_path}':\")\n",
    "    # for folder in subfolders:\n",
    "    #     print(f\"- {folder}\")\n",
    "else:\n",
    "    print(f\"The folder '{test_folder_path}' does not exist.\")\n",
    "\n",
    "# # TODO: se la cartella \n",
    "for subfolder in subfolders:\n",
    "    print(f\"\\nEvaluation on CCPD_{subfolder}\")\n",
    "    subfolder_path = os.path.join(test_folder_path, subfolder) \n",
    "    \n",
    "    sub_df = create_dataframe(subfolder_path, char2idx)\n",
    "\n",
    "    cropped_subfolder =  os.path.join(test_cropped_folder, subfolder)\n",
    "    os.makedirs(cropped_subfolder, exist_ok=True)\n",
    "    cropped_sub_df = create_cropped_dataframe(sub_df, cropped_subfolder)\n",
    "\n",
    "    test_dataset = PlateDataset(cropped_sub_df, transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    test_loss, test_char_acc, test_seq_acc = evaluate_model(model, test_loader, char2idx, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:13:24.099313Z",
     "iopub.status.busy": "2025-07-11T13:13:24.099016Z",
     "iopub.status.idle": "2025-07-11T13:13:24.105015Z",
     "shell.execute_reply": "2025-07-11T13:13:24.104330Z",
     "shell.execute_reply.started": "2025-07-11T13:13:24.099287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:13:24.106053Z",
     "iopub.status.busy": "2025-07-11T13:13:24.105854Z",
     "iopub.status.idle": "2025-07-11T13:13:27.452548Z",
     "shell.execute_reply": "2025-07-11T13:13:27.451496Z",
     "shell.execute_reply.started": "2025-07-11T13:13:24.106033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "subfolder = 'tilt'\n",
    "subfolder_path = subfolder_path = os.path.join(test_folder_path, subfolder)\n",
    "sub_df = create_dataframe(subfolder_path, char2idx)\n",
    "cropped_subfolder =  os.path.join(test_cropped_folder, subfolder)\n",
    "print(cropped_subfolder)\n",
    "os.makedirs(cropped_subfolder, exist_ok=True)\n",
    "\n",
    "cropped_sub_df = create_cropped_dataframe(sub_df, cropped_subfolder)\n",
    "\n",
    "test_dataset = PlateDataset(cropped_sub_df, transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T13:13:27.453774Z",
     "iopub.status.busy": "2025-07-11T13:13:27.453489Z",
     "iopub.status.idle": "2025-07-11T13:13:29.751289Z",
     "shell.execute_reply": "2025-07-11T13:13:29.750120Z",
     "shell.execute_reply.started": "2025-07-11T13:13:27.453747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_batch_images(test_loader, idx2char)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7846535,
     "sourceId": 12439120,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
